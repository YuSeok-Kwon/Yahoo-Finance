"""
ì„¹í„° ë¡œí…Œì´ì…˜ ë¶„ì„ì„ ìœ„í•œ í†µí•© í”¼ì²˜ ìƒì„± ëª¨ë“ˆ

ì´ ëª¨ë“ˆì€ Prophet + XGBoost í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë¸ì„ ìœ„í•œ ëª¨ë“  í”¼ì²˜ ìƒì„± í•¨ìˆ˜ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
1. ê±°ì‹œê²½ì œ ë°ì´í„° ìˆ˜ì§‘ (FRED API)
2. v2 í”¼ì²˜: ê±°ì‹œê²½ì œ, ë ˆì§, ëª¨ë©˜í…€
3. v3 í”¼ì²˜: ì„¹í„° ìƒëŒ€ ëª¨ë©˜í…€, í…Œë§ˆ ê°ì§€
4. v3 í†µí•©: Prophet/XGBoost ëª¨ë¸ ìƒì„±

ì‚¬ìš©ë²•:
    from sector_rotation_features import upgrade_to_v3_features, create_v3_prophet_model

    # v3 í”¼ì²˜ ì¶”ê°€
    sector_panel = upgrade_to_v3_features(df, sector_panel)

    # v3 ëª¨ë¸ ìƒì„±
    prophet_model = create_v3_prophet_model(US_HOLIDAYS, sector_data)

ì‘ì„±ì: nbCamp Project
ë²„ì „: v3.0
ë‚ ì§œ: 2026-01-14
"""

import pandas as pd
import numpy as np
from datetime import datetime
from pathlib import Path

# Optional imports (í•„ìš”í•œ ê²½ìš°ì—ë§Œ ì‚¬ìš©)
try:
    from prophet import Prophet
    PROPHET_AVAILABLE = True
except ImportError:
    PROPHET_AVAILABLE = False

try:
    import xgboost as xgb
    XGB_AVAILABLE = True
except ImportError:
    XGB_AVAILABLE = False


# =============================================================================
# ì„¹ì…˜ 1: ê±°ì‹œê²½ì œ ë°ì´í„° ìˆ˜ì§‘
# =============================================================================

def fetch_fred_data(series_id, start_date='2018-01-01', end_date=None):
    """
    FRED APIë¥¼ í†µí•œ ê±°ì‹œê²½ì œ ë°ì´í„° ìˆ˜ì§‘

    Parameters:
    -----------
    series_id : str
        FRED ì‹œë¦¬ì¦ˆ ID (ì˜ˆ: 'DGS10', 'DCOILWTICO')
    start_date : str
        ì‹œì‘ ë‚ ì§œ (YYYY-MM-DD)
    end_date : str, optional
        ì¢…ë£Œ ë‚ ì§œ (ê¸°ë³¸ê°’: í˜„ì¬)

    Returns:
    --------
    DataFrame : Date, series_id ì»¬ëŸ¼
    """
    try:
        from pandas_datareader import data as web

        if end_date is None:
            end_date = datetime.now().strftime('%Y-%m-%d')

        print(f"  Fetching {series_id} from FRED...")
        df = web.DataReader(series_id, 'fred', start_date, end_date)
        df = df.reset_index()
        df.columns = ['Date', series_id]
        df[series_id] = df[series_id].ffill()

        print(f"   {series_id}: {len(df)} records ({df['Date'].min()} ~ {df['Date'].max()})")
        return df

    except ImportError:
        print("    pandas-datareader not installed. Install with: pip install pandas-datareader")
        return None
    except Exception as e:
        print(f"   Error fetching {series_id}: {str(e)}")
        return None


def create_fallback_macro_data(start_date='2018-01-01', end_date=None):
    """
    FRED API ì‹¤íŒ¨ ì‹œ ë”ë¯¸ ê±°ì‹œê²½ì œ ë°ì´í„° ìƒì„±

    Parameters:
    -----------
    start_date : str
        ì‹œì‘ ë‚ ì§œ
    end_date : str, optional
        ì¢…ë£Œ ë‚ ì§œ

    Returns:
    --------
    DataFrame : Date, DGS10, DCOILWTICO
    """
    if end_date is None:
        end_date = datetime.now().strftime('%Y-%m-%d')

    print("    ë”ë¯¸ ë°ì´í„° ìƒì„± ì¤‘...")

    dates = pd.date_range(start=start_date, end=end_date, freq='D')

    # DGS10: 3% â†’ 4.5% ì¶”ì„¸
    np.random.seed(42)
    base_rate = 3.0
    trend = np.linspace(0, 1.5, len(dates))
    noise = np.random.randn(len(dates)) * 0.1
    dgs10 = base_rate + trend + noise
    dgs10 = np.clip(dgs10, 0.5, 5.0)

    # WTI: 60$ ì¤‘ì‹¬ìœ¼ë¡œ ë³€ë™
    base_oil = 60.0
    oil_trend = np.sin(np.linspace(0, 4*np.pi, len(dates))) * 20
    oil_noise = np.random.randn(len(dates)) * 5
    wti = base_oil + oil_trend + oil_noise
    wti = np.clip(wti, 30, 120)

    df = pd.DataFrame({
        'Date': dates,
        'DGS10': dgs10,
        'DCOILWTICO': wti
    })

    print(f"  Fallback data: {len(df)} records")
    return df


def fetch_and_save_macro_data(data_dir='Data_set', start_date='2018-01-01', end_date=None):
    """
    ê±°ì‹œê²½ì œ ë°ì´í„°ë¥¼ FREDì—ì„œ ê°€ì ¸ì™€ CSVë¡œ ì €ì¥

    Parameters:
    -----------
    data_dir : str or Path
        ì €ì¥ ë””ë ‰í† ë¦¬
    start_date : str
        ì‹œì‘ ë‚ ì§œ
    end_date : str, optional
        ì¢…ë£Œ ë‚ ì§œ

    Returns:
    --------
    DataFrame : ì €ì¥ëœ ê±°ì‹œê²½ì œ ë°ì´í„°
    """
    print("=" * 70)
    print("FRED ê±°ì‹œê²½ì œ ë°ì´í„° ìˆ˜ì§‘")
    print("=" * 70)

    data_path = Path(data_dir)
    data_path.mkdir(exist_ok=True)

    # DGS10, WTI ìˆ˜ì§‘
    print("\n[1/2] DGS10 (10-Year Treasury Rate)")
    dgs10_df = fetch_fred_data('DGS10', start_date, end_date)

    print("\n[2/2] DCOILWTICO (WTI Oil Price)")
    wti_df = fetch_fred_data('DCOILWTICO', start_date, end_date)

    # ë³‘í•©
    if dgs10_df is not None and wti_df is not None:
        macro_df = pd.merge(dgs10_df, wti_df, on='Date', how='outer').sort_values('Date')
        macro_df['DGS10'] = macro_df['DGS10'].ffill().bfill()
        macro_df['DCOILWTICO'] = macro_df['DCOILWTICO'].ffill().bfill()
    else:
        print("\n  FRED API ì‹¤íŒ¨ - ë”ë¯¸ ë°ì´í„° ìƒì„±")
        macro_df = create_fallback_macro_data(start_date, end_date)

    # ì €ì¥
    output_path = data_path / 'macro_data.csv'
    macro_df.to_csv(output_path, index=False)

    print("\n" + "=" * 70)
    print(f"ì €ì¥ ì™„ë£Œ: {output_path}")
    print(f"ë ˆì½”ë“œ: {len(macro_df)}, ê¸°ê°„: {macro_df['Date'].min()} ~ {macro_df['Date'].max()}")
    print("=" * 70)

    return macro_df


# =============================================================================
# ì„¹ì…˜ 2: v2 í”¼ì²˜ ìƒì„±
# =============================================================================

def load_and_prepare_macro(data_dir='Data_set', verbose=True):
    """
    ê±°ì‹œê²½ì œ ë°ì´í„° ë¡œë“œ ë° íŒŒìƒ í”¼ì²˜ ìƒì„±

    ìƒì„± í”¼ì²˜:
    - DGS10_level, DGS10_change_20d, DGS10_zscore_252
    - WTI_log, WTI_mom_3M, WTI_change_20d

    Parameters:
    -----------
    data_dir : str or Path
        ë°ì´í„° ë””ë ‰í† ë¦¬
    verbose : bool
        ì¶œë ¥ ì—¬ë¶€

    Returns:
    --------
    DataFrame : ê±°ì‹œê²½ì œ íŒŒìƒ í”¼ì²˜
    """
    data_path = Path(data_dir) / 'macro_data.csv'

    if not data_path.exists():
        raise FileNotFoundError(f"Macro data not found: {data_path}")

    macro = pd.read_csv(data_path)
    macro['Date'] = pd.to_datetime(macro['Date'])
    macro = macro.sort_values('Date').reset_index(drop=True)

    if verbose:
        print("=" * 70)
        print("ê±°ì‹œê²½ì œ ë°ì´í„° ë¡œë“œ")
        print("=" * 70)
        print(f"  íŒŒì¼: {data_path}")
        print(f"  ê¸°ê°„: {macro['Date'].min()} ~ {macro['Date'].max()}")
        print(f"  ë ˆì½”ë“œ: {len(macro):,}")

    # DGS10 íŒŒìƒ í”¼ì²˜
    macro['DGS10_level'] = macro['DGS10']
    macro['DGS10_change_20d'] = macro['DGS10'].diff(20)

    rolling_mean_252 = macro['DGS10'].rolling(window=252, min_periods=60).mean()
    rolling_std_252 = macro['DGS10'].rolling(window=252, min_periods=60).std()
    macro['DGS10_zscore_252'] = (macro['DGS10'] - rolling_mean_252) / rolling_std_252

    # WTI íŒŒìƒ í”¼ì²˜
    macro['WTI_log'] = np.log(macro['DCOILWTICO'].replace(0, np.nan))
    macro['WTI_mom_3M'] = macro['DCOILWTICO'].pct_change(63)
    macro['WTI_change_20d'] = macro['DCOILWTICO'].diff(20)

    # ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ë° ê·¹ë‹¨ê°’ í´ë¦¬í•‘
    macro = macro.ffill().bfill()
    macro['DGS10_zscore_252'] = macro['DGS10_zscore_252'].clip(-3, 3)
    macro['WTI_mom_3M'] = macro['WTI_mom_3M'].clip(-0.5, 0.5)

    if verbose:
        print("\nìƒì„±ëœ íŒŒìƒ í”¼ì²˜:")
        print("  [DGS10] DGS10_level, DGS10_change_20d, DGS10_zscore_252")
        print("  [WTI] WTI_log, WTI_mom_3M, WTI_change_20d")

    return macro


def merge_macro_to_sector_panel(sector_panel, macro_df, verbose=True):
    """
    ì„¹í„° íŒ¨ë„ì— ê±°ì‹œê²½ì œ ë°ì´í„° ë³‘í•© (ê±°ë˜ì¼ ìº˜ë¦°ë” ê¸°ì¤€)

    Parameters:
    -----------
    sector_panel : DataFrame
        ì„¹í„° íŒ¨ë„ (ds ë˜ëŠ” Date í•„ìˆ˜)
    macro_df : DataFrame
        ê±°ì‹œê²½ì œ ë°ì´í„°
    verbose : bool
        ì¶œë ¥ ì—¬ë¶€

    Returns:
    --------
    DataFrame : ë³‘í•©ëœ ì„¹í„° íŒ¨ë„
    """
    panel = sector_panel.copy()
    macro = macro_df.copy()

    # Date ì»¬ëŸ¼ í†µì¼
    if 'ds' in panel.columns and 'Date' not in panel.columns:
        panel['Date'] = pd.to_datetime(panel['ds'])
    elif 'Date' not in panel.columns:
        raise ValueError("sector_panel must have 'ds' or 'Date' column")

    panel['Date'] = pd.to_datetime(panel['Date'])
    macro['Date'] = pd.to_datetime(macro['Date'])

    # ê±°ë˜ì¼ ê¸°ì¤€ ë³‘í•©
    trading_dates = panel['Date'].unique()
    macro_trading = macro.set_index('Date').reindex(trading_dates, method='ffill').reset_index()
    macro_trading.columns = ['Date'] + [c for c in macro_trading.columns if c != 'Date']

    macro_cols = [c for c in macro_trading.columns if c not in ['Date', 'DGS10', 'DCOILWTICO']]
    panel = panel.merge(macro_trading[['Date'] + macro_cols], on='Date', how='left')

    # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
    if 'Sector' in panel.columns:
        panel = panel.groupby('Sector', group_keys=False).apply(lambda x: x.ffill().bfill())
    else:
        panel = panel.ffill().bfill()

    if verbose:
        print("\n ê±°ì‹œê²½ì œ ë°ì´í„° ë³‘í•© ì™„ë£Œ")
        print(f"  ì¶”ê°€ëœ ì»¬ëŸ¼: {len(macro_cols)}ê°œ")
        print(f"  ìµœì¢… Shape: {panel.shape}")

    return panel


def add_regime_features(sector_panel, window=252, verbose=True):
    """
    ë ˆì§ í”¼ì²˜ ì¶”ê°€

    ìƒì„± í”¼ì²˜:
    - Market_Vol: ì‹œì¥ ì „ì²´ ë³€ë™ì„±
    - CrossSection_Dispersion: ì„¹í„° ê°„ ìˆ˜ìµë¥  ë¶„ì‚°

    Parameters:
    -----------
    sector_panel : DataFrame
        ì„¹í„° íŒ¨ë„
    window : int
        ê³„ì‚° ìœˆë„ìš°
    verbose : bool
        ì¶œë ¥ ì—¬ë¶€

    Returns:
    --------
    DataFrame : ë ˆì§ í”¼ì²˜ ì¶”ê°€ëœ íŒ¨ë„
    """
    panel = sector_panel.copy()

    if 'Date' not in panel.columns and 'ds' in panel.columns:
        panel['Date'] = panel['ds']

    panel['Date'] = pd.to_datetime(panel['Date'])

    # Market_Vol
    if 'Avg_Volatility_20d' in panel.columns:
        market_vol = panel.groupby('Date')['Avg_Volatility_20d'].mean().to_frame('Market_Vol')
    elif 'Volatility_20d' in panel.columns:
        market_vol = panel.groupby('Date')['Volatility_20d'].mean().to_frame('Market_Vol')
    else:
        daily_ret = panel.groupby('Date')['Daily_Return'].mean()
        market_vol = daily_ret.rolling(window=20).std().to_frame('Market_Vol') * np.sqrt(252)
        market_vol = market_vol.reset_index()

    # CrossSection_Dispersion
    if 'Daily_Return' in panel.columns:
        cross_dispersion = panel.groupby('Date')['Daily_Return'].std().to_frame('CrossSection_Dispersion')
    elif 'Avg_Daily_Return_raw' in panel.columns:
        cross_dispersion = panel.groupby('Date')['Avg_Daily_Return_raw'].std().to_frame('CrossSection_Dispersion')
    else:
        cross_dispersion = pd.DataFrame({
            'Date': panel['Date'].unique(),
            'CrossSection_Dispersion': 0.01
        })

    # ë³‘í•©
    if not isinstance(market_vol, pd.DataFrame):
        market_vol = market_vol.reset_index()
    if not isinstance(cross_dispersion, pd.DataFrame):
        cross_dispersion = cross_dispersion.reset_index()

    panel = panel.merge(market_vol, on='Date', how='left')
    panel = panel.merge(cross_dispersion, on='Date', how='left')

    panel['Market_Vol'] = panel['Market_Vol'].ffill().fillna(0.2)
    panel['CrossSection_Dispersion'] = panel['CrossSection_Dispersion'].ffill().fillna(0.01)

    if verbose:
        print("\n ë ˆì§ í”¼ì²˜ ì¶”ê°€ ì™„ë£Œ")
        print("  - Market_Vol, CrossSection_Dispersion")

    return panel


def add_momentum_features(sector_panel, verbose=True):
    """
    ë‹¨ê¸° ëª¨ë©˜í…€ í”¼ì²˜ ì¶”ê°€

    ìƒì„± í”¼ì²˜:
    - Mom_1M, Mom_6M, Mom_Accel

    Parameters:
    -----------
    sector_panel : DataFrame
        ì„¹í„° íŒ¨ë„
    verbose : bool
        ì¶œë ¥ ì—¬ë¶€

    Returns:
    --------
    DataFrame : ëª¨ë©˜í…€ í”¼ì²˜ ì¶”ê°€ëœ íŒ¨ë„
    """
    panel = sector_panel.copy()

    def calc_momentum(group):
        group['Mom_1M'] = group['Index'].pct_change(21)
        group['Mom_6M'] = group['Index'].pct_change(126)
        group['Mom_Accel'] = group['Mom_1M'] - group['Mom_6M']
        return group

    if 'Sector' in panel.columns:
        panel = panel.groupby('Sector', group_keys=False).apply(calc_momentum)
    else:
        panel = calc_momentum(panel)

    # ê²°ì¸¡ì¹˜ ë° ê·¹ë‹¨ê°’ ì²˜ë¦¬
    for col in ['Mom_1M', 'Mom_6M', 'Mom_Accel']:
        panel[col] = panel[col].fillna(0).clip(-0.5, 0.5)

    if verbose:
        print("\n ëª¨ë©˜í…€ í”¼ì²˜ ì¶”ê°€ ì™„ë£Œ")
        print("  - Mom_1M, Mom_6M, Mom_Accel")

    return panel


def calculate_dynamic_cps(sector_data, base_cps=0.05, window=252):
    """
    ì„¹í„° ë³€ë™ì„± ê¸°ë°˜ ë™ì  changepoint_prior_scale ê³„ì‚°

    Parameters:
    -----------
    sector_data : DataFrame
        ì„¹í„° ë°ì´í„°
    base_cps : float
        ê¸°ë³¸ cps
    window : int
        ê³„ì‚° ìœˆë„ìš°

    Returns:
    --------
    float : ê³„ì‚°ëœ cps ê°’
    """
    if 'Avg_Volatility_20d' in sector_data.columns:
        recent_vol = sector_data.tail(window)['Avg_Volatility_20d'].mean()
    elif 'Volatility_20d' in sector_data.columns:
        recent_vol = sector_data.tail(window)['Volatility_20d'].mean()
    else:
        return base_cps

    if recent_vol > 0.40:
        return 0.10
    elif recent_vol > 0.30:
        return 0.05
    else:
        return 0.03


# =============================================================================
# ì„¹ì…˜ 3: v3 í”¼ì²˜ ìƒì„±
# =============================================================================

def add_relative_momentum_features(sector_panel, windows=[21, 63, 126], verbose=True):
    """
    ğŸ¥‡ 1ìˆœìœ„: ì„¹í„° ìƒëŒ€ ëª¨ë©˜í…€ í”¼ì²˜ ì¶”ê°€

    í•µì‹¬ ê°œë…:
    - ì ˆëŒ€ ìˆ˜ìµë¥ ì´ ì•„ë‹Œ ì‹œì¥ ëŒ€ë¹„ ìƒëŒ€ ìˆ˜ìµë¥  ì‚¬ìš©
    - 2023ë…„ Techì˜ "ì‹œì¥ ëŒ€ë¹„ ì••ë„ì  ê°•ì„¸" í¬ì°©

    ìƒì„± í”¼ì²˜:
    - RelMom_1M, RelMom_3M, RelMom_6M, RelMom_Accel
    - Relative_Mom_{window}d_diff, Relative_Mom_{window}d_ratio

    Parameters:
    -----------
    sector_panel : DataFrame
        ì„¹í„° íŒ¨ë„ (Date, Sector, Index í•„ìš”)
    windows : list
        ëª¨ë©˜í…€ ìœˆë„ìš° (ì¼ ë‹¨ìœ„) [21=1M, 63=3M, 126=6M]
    verbose : bool
        ì¶œë ¥ ì—¬ë¶€

    Returns:
    --------
    DataFrame : ìƒëŒ€ ëª¨ë©˜í…€ í”¼ì²˜ ì¶”ê°€ëœ íŒ¨ë„
    """
    panel = sector_panel.copy()

    if 'Date' not in panel.columns and 'ds' in panel.columns:
        panel['Date'] = panel['ds']

    panel['Date'] = pd.to_datetime(panel['Date'])
    panel = panel.sort_values(['Date', 'Sector'])

    # 1. ì‹œì¥ ì „ì²´ ìˆ˜ìµë¥  (ëª¨ë“  ì„¹í„° í‰ê· )
    market_index = panel.groupby('Date')['Index'].mean().to_frame('Market_Index')

    # 2. ì‹œì¥ ìˆ˜ìµë¥  ê³„ì‚°
    for window in windows:
        market_index[f'Market_Return_{window}d'] = market_index['Market_Index'].pct_change(window)

    # 3. ì„¹í„° íŒ¨ë„ì— ì‹œì¥ ìˆ˜ìµë¥  ë³‘í•©
    panel = panel.merge(market_index, on='Date', how='left')

    # 4. ì„¹í„°ë³„ ì ˆëŒ€ ìˆ˜ìµë¥  ê³„ì‚°
    def calc_sector_returns(group):
        for window in windows:
            group[f'Sector_Return_{window}d'] = group['Index'].pct_change(window)
        return group

    panel = panel.groupby('Sector', group_keys=False).apply(calc_sector_returns)

    # 5. ìƒëŒ€ ëª¨ë©˜í…€ ê³„ì‚° (Sector - Market)
    for window in windows:
        sector_col = f'Sector_Return_{window}d'
        market_col = f'Market_Return_{window}d'

        # ì°¨ì´ (Difference)
        panel[f'Relative_Mom_{window}d_diff'] = panel[sector_col] - panel[market_col]

        # ë¹„ìœ¨ (Ratio) - ë¡œê·¸ ë³€í™˜
        panel[f'Relative_Mom_{window}d_ratio'] = (
            np.log1p(panel[sector_col]) - np.log1p(panel[market_col])
        )

    # 6. ê²°ì¸¡ì¹˜ ë° ê·¹ë‹¨ê°’ ì²˜ë¦¬
    relative_cols = [c for c in panel.columns if 'Relative_Mom' in c]
    for col in relative_cols:
        panel[col] = panel[col].fillna(0).clip(-0.5, 0.5)

    # 7. ë‹¨ì¶• ì»¬ëŸ¼ëª…
    panel['RelMom_1M'] = panel['Relative_Mom_21d_diff']
    panel['RelMom_3M'] = panel['Relative_Mom_63d_diff']
    panel['RelMom_6M'] = panel['Relative_Mom_126d_diff']

    # 8. ìƒëŒ€ ëª¨ë©˜í…€ ê°€ì†ë„
    panel['RelMom_Accel'] = panel['RelMom_1M'] - panel['RelMom_6M']

    if verbose:
        print("\n ì„¹í„° ìƒëŒ€ ëª¨ë©˜í…€ í”¼ì²˜ ì¶”ê°€ ì™„ë£Œ")
        print("  - Relative_Mom_21d/63d/126d_diff/ratio")
        print("  - RelMom_1M/3M/6M, RelMom_Accel")
        print("   2023ë…„ Tech ê°™ì€ 'ì‹œì¥ ëŒ€ë¹„ ê°•ì„¸' í¬ì°©!")

    return panel


def add_theme_detection_features(df, sector_panel, verbose=True):
    """
     3ìˆœìœ„: í…Œë§ˆ ê°ì§€ í”¼ì²˜ ì¶”ê°€

    í•µì‹¬ ê°œë…:
    - 2023 AI ë¶ì²˜ëŸ¼ íŠ¹ì • í…Œë§ˆë¡œ ì ë¦¼ ê°ì§€
    - ìƒìœ„ ì†Œìˆ˜ ì¢…ëª©ì— ê±°ë˜ ì§‘ì¤‘ë„ ì¸¡ì •

    ìƒì„± í”¼ì²˜:
    - BigTech_Concentration: ì„¹í„° ë‚´ ìƒìœ„ 3ì¢…ëª© ê±°ë˜ëŒ€ê¸ˆ ë¹„ì¤‘
    - Hot_Stock_Ratio: Vol_Z_Score ìƒìœ„ 10% ì¢…ëª© ë¹„ì¤‘
    - Relative_Theme_Strength: ì„¹í„° vs ì‹œì¥ í…Œë§ˆ ê°•ë„

    Parameters:
    -----------
    df : DataFrame
        ì¢…ëª©ë³„ ë°ì´í„° (Company, Sector, Volume, Close í•„ìš”)
    sector_panel : DataFrame
        ì„¹í„° íŒ¨ë„
    verbose : bool
        ì¶œë ¥ ì—¬ë¶€

    Returns:
    --------
    DataFrame : í…Œë§ˆ ê°ì§€ í”¼ì²˜ ì¶”ê°€ëœ íŒ¨ë„
    """
    panel = sector_panel.copy()

    if 'Date' not in panel.columns and 'ds' in panel.columns:
        panel['Date'] = panel['ds']

    panel['Date'] = pd.to_datetime(panel['Date'])

    # 1. ê±°ë˜ëŒ€ê¸ˆ ê³„ì‚°
    df_theme = df.copy()
    df_theme['Trade_Value'] = df_theme['Volume'] * df_theme['Close']

    # 2. BigTech Concentration
    def calc_bigtech_concentration(group):
        if len(group) < 3:
            return 0.0
        total_value = group['Trade_Value'].sum()
        if total_value == 0:
            return 0.0
        top3_value = group.nlargest(3, 'Trade_Value')['Trade_Value'].sum()
        return top3_value / total_value

    bigtech_conc = df_theme.groupby(['Date', 'Sector']).apply(
        calc_bigtech_concentration
    ).reset_index(name='BigTech_Concentration')

    # 3. Hot Stock Ratio
    if 'Vol_Z_Score' in df_theme.columns:
        def calc_hot_stock_ratio(group):
            if len(group) == 0:
                return 0.0
            threshold = group['Vol_Z_Score'].quantile(0.90)
            hot_count = (group['Vol_Z_Score'] >= threshold).sum()
            return hot_count / len(group)

        hot_stock = df_theme.groupby(['Date', 'Sector']).apply(
            calc_hot_stock_ratio
        ).reset_index(name='Hot_Stock_Ratio')
    else:
        # Fallback: ê±°ë˜ëŸ‰ ê¸°ë°˜
        def calc_hot_stock_ratio_vol(group):
            if len(group) == 0:
                return 0.0
            threshold = group['Volume'].quantile(0.90)
            hot_count = (group['Volume'] >= threshold).sum()
            return hot_count / len(group)

        hot_stock = df_theme.groupby(['Date', 'Sector']).apply(
            calc_hot_stock_ratio_vol
        ).reset_index(name='Hot_Stock_Ratio')

    # 4. ì„¹í„° íŒ¨ë„ì— ë³‘í•©
    panel = panel.merge(bigtech_conc, on=['Date', 'Sector'], how='left')
    panel = panel.merge(hot_stock, on=['Date', 'Sector'], how='left')

    # 5. ê²°ì¸¡ì¹˜ ì²˜ë¦¬
    panel['BigTech_Concentration'] = panel['BigTech_Concentration'].fillna(0.33)
    panel['Hot_Stock_Ratio'] = panel['Hot_Stock_Ratio'].fillna(0.10)

    # 6. ì‹œì¥ ì „ì²´ í…Œë§ˆ ê°•ë„
    market_theme = panel.groupby('Date')[['BigTech_Concentration', 'Hot_Stock_Ratio']].mean()
    market_theme.columns = ['Market_BigTech_Conc', 'Market_Hot_Ratio']

    panel = panel.merge(market_theme, on='Date', how='left')

    # 7. ìƒëŒ€ í…Œë§ˆ ê°•ë„
    panel['Relative_Theme_Strength'] = (
        panel['BigTech_Concentration'] - panel['Market_BigTech_Conc']
    )

    if verbose:
        print("\n í…Œë§ˆ ê°ì§€ í”¼ì²˜ ì¶”ê°€ ì™„ë£Œ")
        print("  - BigTech_Concentration, Hot_Stock_Ratio")
        print("  - Relative_Theme_Strength")
        print("   2023 AI ë¶ ê°™ì€ í…Œë§ˆì¥ íƒì§€!")

    return panel


def prepare_rank_signal_target(train_data, year):
    """
     2ìˆœìœ„: XGBoost Rank Signal ëª©í‘œ ì¤€ë¹„

    í•µì‹¬ ê°œë…:
    - ì ˆëŒ€ ìˆ˜ìµë¥ ì´ ì•„ë‹Œ ìƒëŒ€ ê°•ë„ë¥¼ ëª©í‘œë¡œ ì‚¬ìš©
    - "ëˆ„ê°€ ë” ë‚˜ì€ê°€?" ìˆœìœ„ ì˜ˆì¸¡ì— ìµœì í™”

    Parameters:
    -----------
    train_data : DataFrame
        í•™ìŠµ ë°ì´í„° (ds, Sector, y í•„ìš”)
    year : int
        ì˜ˆì¸¡ ì—°ë„

    Returns:
    --------
    DataFrame : rank signalì´ ì¶”ê°€ëœ ë°ì´í„°
    """
    data = train_data.copy()
    data['Date'] = pd.to_datetime(data['ds'])
    data['Year'] = data['Date'].dt.year

    # ì—°ë„ë³„ ì„¹í„° ëˆ„ì  ìˆ˜ìµë¥ 
    def calc_annual_rank(group):
        if len(group) < 2:
            return group

        start_idx = group['y'].iloc[0]
        end_idx = group['y'].iloc[-1]
        cumulative_return = np.exp(end_idx) - np.exp(start_idx)

        group['Annual_Return'] = cumulative_return
        return group

    data = data.groupby(['Year', 'Sector'], group_keys=False).apply(calc_annual_rank)

    # ì—°ë„ë³„ ì‹œì¥ í‰ê· 
    market_return = data.groupby('Year')['Annual_Return'].mean().to_frame('Market_Return_Year')
    data = data.merge(market_return, on='Year', how='left')

    # ìƒëŒ€ ê°•ë„ = ì„¹í„° - ì‹œì¥
    data['Relative_Strength'] = data['Annual_Return'] - data['Market_Return_Year']

    # ìˆœìœ„
    data['Rank_Signal'] = data.groupby('Year')['Relative_Strength'].rank(ascending=False, method='min')

    return data


# =============================================================================
# ì„¹ì…˜ 4: v3 í†µí•© í•¨ìˆ˜
# =============================================================================

def upgrade_to_v3_features(df, sector_panel, verbose=True):
    """
    ê¸°ì¡´ v2 sector_panelì„ v3ìœ¼ë¡œ ì—…ê·¸ë ˆì´ë“œ

    í•œ ì¤„ë¡œ v3 í”¼ì²˜ ì¶”ê°€!

    Parameters:
    -----------
    df : DataFrame
        ì¢…ëª©ë³„ ë°ì´í„°
    sector_panel : DataFrame
        v2 ì„¹í„° íŒ¨ë„ (ê±°ì‹œê²½ì œ/ë ˆì§/ëª¨ë©˜í…€ í¬í•¨)
    verbose : bool
        ì¶œë ¥ ì—¬ë¶€

    Returns:
    --------
    DataFrame : v3 í”¼ì²˜ ì¶”ê°€ëœ ì„¹í„° íŒ¨ë„
    """
    if verbose:
        print("=" * 70)
        print(" v3 ì—…ê·¸ë ˆì´ë“œ ì‹œì‘")
        print("=" * 70)
        print(f"ì…ë ¥ Shape: {sector_panel.shape}")

    # 1. ì„¹í„° ìƒëŒ€ ëª¨ë©˜í…€
    panel = add_relative_momentum_features(sector_panel, verbose=verbose)

    # 2. í…Œë§ˆ ê°ì§€
    panel = add_theme_detection_features(df, panel, verbose=verbose)

    if verbose:
        print("\n" + "=" * 70)
        print(" v3 ì—…ê·¸ë ˆì´ë“œ ì™„ë£Œ")
        print("=" * 70)
        print(f"ìµœì¢… Shape: {panel.shape}")

        v3_cols = [c for c in panel.columns if any(x in c for x in
                   ['RelMom', 'Relative_Mom', 'BigTech', 'Hot_Stock', 'Theme'])]
        print(f"\nì¶”ê°€ëœ v3 í”¼ì²˜ ({len(v3_cols)}ê°œ):")
        for col in v3_cols[:15]:
            print(f"  - {col}")
        if len(v3_cols) > 15:
            print(f"  ... ì™¸ {len(v3_cols) - 15}ê°œ")

    return panel


def apply_v3_enhancements(df, sector_panel, verbose=True):
    """
    v3 ëª¨ë“  ê°œì„ ì‚¬í•­ ì ìš© (upgrade_to_v3_featuresì˜ alias)

    ê¸°ì¡´ ë…¸íŠ¸ë¶ í˜¸í™˜ì„±ì„ ìœ„í•œ í•¨ìˆ˜ì…ë‹ˆë‹¤.
    ë‚´ë¶€ì ìœ¼ë¡œ upgrade_to_v3_features()ë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.

    Parameters:
    -----------
    df : DataFrame
        ì¢…ëª©ë³„ ë°ì´í„°
    sector_panel : DataFrame
        ì„¹í„° íŒ¨ë„
    verbose : bool
        ì¶œë ¥ ì—¬ë¶€

    Returns:
    --------
    DataFrame : v3 ê°œì„  í”¼ì²˜ê°€ ëª¨ë‘ ì¶”ê°€ëœ ì„¹í„° íŒ¨ë„
    """
    if verbose:
        print("=" * 70)
        print(" v3 í•µì‹¬ ê°œì„ ì‚¬í•­ ì ìš©")
        print("=" * 70)

    # upgrade_to_v3_featuresì™€ ë™ì¼í•œ ê¸°ëŠ¥
    panel = add_relative_momentum_features(sector_panel, verbose=verbose)
    panel = add_theme_detection_features(df, panel, verbose=verbose)

    if verbose:
        print("\n" + "=" * 70)
        print(" v3 ê°œì„  ì™„ë£Œ")
        print("=" * 70)
        print(f"ìµœì¢… Shape: {panel.shape}")
        print(f"\nì¶”ê°€ëœ v3 í”¼ì²˜:")
        v3_cols = [c for c in panel.columns if any(x in c for x in ['Relative_Mom', 'RelMom', 'BigTech', 'Hot_Stock', 'Theme'])]
        for col in v3_cols[:10]:
            print(f"  - {col}")
        if len(v3_cols) > 10:
            print(f"  ... ì™¸ {len(v3_cols) - 10}ê°œ")

    return panel


def create_v3_prophet_model(holidays_df, sector_data=None, base_cps=0.05):
    """
    v3 Prophet ëª¨ë¸ ìƒì„± (v2 + v3 regressor)

    Parameters:
    -----------
    holidays_df : DataFrame
        íœ´ì¼ ë°ì´í„°
    sector_data : DataFrame, optional
        ì„¹í„° ë°ì´í„° (dynamic cps ê³„ì‚°ìš©)
    base_cps : float
        ê¸°ë³¸ changepoint_prior_scale

    Returns:
    --------
    Prophet : v3 regressorê°€ ì¶”ê°€ëœ Prophet ëª¨ë¸
    """
    if not PROPHET_AVAILABLE:
        raise ImportError("Prophet not installed. Install with: pip install prophet")

    # Dynamic cps
    if sector_data is not None:
        cps = calculate_dynamic_cps(sector_data, base_cps)
    else:
        cps = base_cps

    # Prophet ëª¨ë¸
    model = Prophet(
        yearly_seasonality=True,
        weekly_seasonality=False,
        daily_seasonality=False,
        changepoint_prior_scale=cps,
        seasonality_prior_scale=10,
        holidays=holidays_df,
        holidays_prior_scale=10
    )

    # v2 ê¸°ë³¸ regressor
    base_regressors = [
        'Avg_Volatility_20d', 'Avg_RSI_14', 'Avg_ATR_14',
        'DGS10_level', 'DGS10_change_20d', 'WTI_log', 'WTI_mom_3M',
        'Market_Vol', 'CrossSection_Dispersion',
        'Mom_1M', 'Mom_6M', 'Mom_Accel'
    ]

    # v3 regressor
    v3_regressors = [
        'RelMom_1M', 'RelMom_3M', 'RelMom_6M', 'RelMom_Accel',
        'BigTech_Concentration', 'Hot_Stock_Ratio', 'Relative_Theme_Strength'
    ]

    all_regressors = base_regressors + v3_regressors

    for reg in all_regressors:
        model.add_regressor(reg)

    print(f" v3 Prophet ëª¨ë¸ ìƒì„± ì™„ë£Œ (cps={cps:.3f})")
    print(f"   - ê¸°ë³¸ regressor: {len(base_regressors)}ê°œ")
    print(f"   - v3 regressor: {len(v3_regressors)}ê°œ")
    print(f"   - ì´ regressor: {len(all_regressors)}ê°œ")

    return model


def train_v3_xgb_model(train_data, prophet_forecast,
                       use_rank_signal=True,
                       use_early_stopping=True,
                       val_ratio=0.2,
                       verbose=True):
    """
    v3 XGBoost ëª¨ë¸ í•™ìŠµ (Rank Signal ëª©í‘œ)

     í•µì‹¬: targetì„ residualì´ ì•„ë‹Œ relative_strengthë¡œ ë³€ê²½

    Parameters:
    -----------
    train_data : DataFrame
        í•™ìŠµ ë°ì´í„°
    prophet_forecast : DataFrame
        Prophet ì˜ˆì¸¡
    use_rank_signal : bool
        Rank Signal ì‚¬ìš© ì—¬ë¶€
    use_early_stopping : bool
        ì¡°ê¸° ì¢…ë£Œ ì‚¬ìš© ì—¬ë¶€
    val_ratio : float
        ê²€ì¦ ì„¸íŠ¸ ë¹„ìœ¨
    verbose : bool
        ì¶œë ¥ ì—¬ë¶€

    Returns:
    --------
    tuple : (xgb_model, feature_cols)
    """
    if not XGB_AVAILABLE:
        raise ImportError("XGBoost not installed. Install with: pip install xgboost")

    merged = train_data.merge(
        prophet_forecast[['ds', 'yhat']],
        on='ds',
        how='inner'
    )

    if verbose:
        print("=" * 70)
        print(" v3 XGBoost í•™ìŠµ ì‹œì‘")
        print("=" * 70)
        print(f"í•™ìŠµ ë°ì´í„°: {len(merged)} rows")

    # Rank Signal ëª©í‘œ
    if use_rank_signal:
        market_y = merged.groupby('ds')['y'].mean().to_frame('market_y')
        merged = merged.merge(market_y, on='ds', how='left')
        merged['relative_strength'] = merged['y'] - merged['market_y']

        market_yhat = merged.groupby('ds')['yhat'].mean().to_frame('market_yhat')
        merged = merged.merge(market_yhat, on='ds', how='left')
        merged['relative_yhat'] = merged['yhat'] - merged['market_yhat']

        merged['target'] = merged['relative_strength'] - merged['relative_yhat']

        if verbose:
            print(" Rank Signal ëª©í‘œ ì‚¬ìš©")
    else:
        merged['target'] = merged['y'] - merged['yhat']
        if verbose:
            print("  ê¸°ì¡´ Residual ëª©í‘œ ì‚¬ìš©")

    # í”¼ì²˜ ì»¬ëŸ¼
    feature_cols = [
        'yhat',
        'Avg_Volatility_20d', 'Avg_RSI_14', 'Avg_ATR_14',
        'DGS10_level', 'DGS10_change_20d', 'WTI_log', 'WTI_mom_3M',
        'Market_Vol', 'CrossSection_Dispersion',
        'Mom_1M', 'Mom_6M', 'Mom_Accel',
        'RelMom_1M', 'RelMom_3M', 'RelMom_6M', 'RelMom_Accel',
        'BigTech_Concentration', 'Hot_Stock_Ratio', 'Relative_Theme_Strength'
    ]

    available_features = [f for f in feature_cols if f in merged.columns]

    if verbose:
        print(f"ì‚¬ìš© ê°€ëŠ¥í•œ í”¼ì²˜: {len(available_features)}ê°œ")

    X = merged[available_features].values
    y = merged['target'].values
    X = np.nan_to_num(X, nan=0.0)

    # Train/Val ë¶„í• 
    if use_early_stopping:
        n_train = int(len(X) * (1 - val_ratio))
        X_train, X_val = X[:n_train], X[n_train:]
        y_train, y_val = y[:n_train], y[n_train:]
    else:
        X_train, y_train = X, y

    # XGBoost
    xgb_model = xgb.XGBRegressor(
        n_estimators=200,
        max_depth=4,
        learning_rate=0.05,
        subsample=0.8,
        colsample_bytree=0.8,
        random_state=42
    )

    if use_early_stopping:
        xgb_model.fit(
            X_train, y_train,
            eval_set=[(X_val, y_val)],
            early_stopping_rounds=20,
            verbose=False
        )
        if verbose:
            print(f" Early Stopping: {xgb_model.best_iteration} iterations")
    else:
        xgb_model.fit(X_train, y_train)

    if verbose:
        print("=" * 70)
        print(" v3 XGBoost í•™ìŠµ ì™„ë£Œ")
        print("=" * 70)

    return xgb_model, available_features


# =============================================================================
# ë©”ì¸ í•¨ìˆ˜
# =============================================================================

if __name__ == '__main__':
    print("=" * 70)
    print("Sector Rotation Features Module (v3)")
    print("=" * 70)
    print("\n ì‚¬ìš© ê°€ëŠ¥í•œ í•¨ìˆ˜:")
    print("\n[ë°ì´í„° ìˆ˜ì§‘]")
    print("  - fetch_and_save_macro_data()")
    print("\n[v2 í”¼ì²˜]")
    print("  - load_and_prepare_macro()")
    print("  - merge_macro_to_sector_panel()")
    print("  - add_regime_features()")
    print("  - add_momentum_features()")
    print("\n[v3 í”¼ì²˜]")
    print("  - add_relative_momentum_features()  ")
    print("  - add_theme_detection_features()    ")
    print("\n[v3 í†µí•©]")
    print("  - upgrade_to_v3_features()")
    print("  - apply_v3_enhancements()           (alias)")
    print("  - create_v3_prophet_model()")
    print("  - train_v3_xgb_model()              ")
    print("\n=" * 70)
