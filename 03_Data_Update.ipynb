{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. Data Update & Quality Assurance\n",
    "\n",
    "---\n",
    "\n",
    "## 목표\n",
    "1. 기존 데이터(2018-11-29 ~ 2023-11-29) 품질 검증\n",
    "2. 신규 데이터(2023-11-30 ~ 현재) 수집 및 병합\n",
    "3. 섹터/산업 메타데이터 최신화\n",
    "4. 파생변수 재계산 (기존 + RSI, Bollinger Bands)\n",
    "\n",
    "## 주요 고려사항\n",
    "- Adjusted Close(수정 종가) 정합성 검증\n",
    "- 상폐/티커 변경 종목 예외 처리\n",
    "- 기업별 관측일 불일치 분석\n",
    "- OHLC 이상치 검출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 1. 환경 설정 & 기존 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T04:49:26.479330Z",
     "iopub.status.busy": "2026-01-12T04:49:26.478636Z",
     "iopub.status.idle": "2026-01-12T04:49:27.067039Z",
     "shell.execute_reply": "2026-01-12T04:49:27.066618Z"
    }
   },
   "outputs": [],
   "source": [
    "# Library Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 시각화 설정\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T04:49:27.068387Z",
     "iopub.status.busy": "2026-01-12T04:49:27.068267Z",
     "iopub.status.idle": "2026-01-12T04:49:27.070204Z",
     "shell.execute_reply": "2026-01-12T04:49:27.069860Z"
    }
   },
   "outputs": [],
   "source": [
    "# 경로 설정\n",
    "PROJECT_ROOT = Path('.').resolve()\n",
    "DATA_DIR = PROJECT_ROOT / 'Data_set'\n",
    "QA_DIR = DATA_DIR / 'QA'\n",
    "LOG_DIR = DATA_DIR / 'Logs'\n",
    "\n",
    "# 디렉토리 생성\n",
    "QA_DIR.mkdir(exist_ok=True)\n",
    "LOG_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T04:49:27.071110Z",
     "iopub.status.busy": "2026-01-12T04:49:27.071049Z",
     "iopub.status.idle": "2026-01-12T04:49:28.297854Z",
     "shell.execute_reply": "2026-01-12T04:49:28.297437Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기존 데이터 Shape: (602962, 26)\n",
      "기간: 2018-11-29 ~ 2023-11-29\n",
      "기업 수: 491\n",
      "\n",
      "컬럼 목록:\n",
      "['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits', 'Company', 'Sector', 'Daily_Return', 'Cum_Return', 'MA_5', 'MA_20', 'MA_60', 'Volatility_20d', 'Cum_Max', 'Drawdown', 'MDD', 'Vol_MA_20', 'Vol_Ratio', 'Vol_Std_20', 'Vol_Z_Score', 'Prev_Close', 'Gap', 'Gap_Pct']\n"
     ]
    }
   ],
   "source": [
    "# 기존 데이터 로드\n",
    "df_existing = pd.read_csv(DATA_DIR / 'stock_daily_master.csv')\n",
    "df_existing['Date'] = pd.to_datetime(df_existing['Date'])\n",
    "\n",
    "print(f\"기존 데이터 Shape: {df_existing.shape}\")\n",
    "print(f\"기간: {df_existing['Date'].min().strftime('%Y-%m-%d')} ~ {df_existing['Date'].max().strftime('%Y-%m-%d')}\")\n",
    "print(f\"기업 수: {df_existing['Company'].nunique()}\")\n",
    "print(f\"\\n컬럼 목록:\")\n",
    "print(df_existing.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T04:49:28.311840Z",
     "iopub.status.busy": "2026-01-12T04:49:28.311732Z",
     "iopub.status.idle": "2026-01-12T04:49:28.323260Z",
     "shell.execute_reply": "2026-01-12T04:49:28.322992Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 티커 수: 491\n",
      "샘플: ['A', 'AAPL', 'ABBV', 'ABEV', 'ABNB', 'ABT', 'ACGL', 'ACN', 'ADBE', 'ADI', 'ADM', 'ADP', 'ADSK', 'AEE', 'AEM', 'AEP', 'AFL', 'AIG', 'AJG', 'ALC']\n"
     ]
    }
   ],
   "source": [
    "# 티커 목록 추출\n",
    "tickers = df_existing['Company'].unique().tolist()\n",
    "print(f\"총 티커 수: {len(tickers)}\")\n",
    "print(f\"샘플: {tickers[:20]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 2. 데이터 품질 검증 (QA)\n",
    "\n",
    "### 검증 항목\n",
    "1. 기업별 관측일 수 분석 (동일 기간 비교 가능 여부)\n",
    "2. OHLC 이상치 검증\n",
    "3. Dividends & Stock Splits 이벤트 분석\n",
    "4. 수익률 결측치 처리 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 기업별 관측일 수 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T04:49:28.324574Z",
     "iopub.status.busy": "2026-01-12T04:49:28.324511Z",
     "iopub.status.idle": "2026-01-12T04:49:28.353939Z",
     "shell.execute_reply": "2026-01-12T04:49:28.353642Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "기업별 관측일 수 통계\n",
      "============================================================\n",
      "         Obs_Count    Days_Span\n",
      "count   491.000000   491.000000\n",
      "mean   1228.028513  1782.358452\n",
      "std     142.004194   206.450908\n",
      "min      54.000000    76.000000\n",
      "25%    1258.000000  1826.000000\n",
      "50%    1258.000000  1826.000000\n",
      "75%    1258.000000  1826.000000\n",
      "max    1258.000000  1826.000000\n",
      "\n",
      "기대 관측일 수 (5년): ~1,258일 (252 거래일 x 5년)\n",
      "  Company  Obs_Count Start_Date   End_Date  Days_Span\n",
      "0       A       1258 2018-11-29 2023-11-29       1826\n",
      "1    AAPL       1258 2018-11-29 2023-11-29       1826\n",
      "2    ABBV       1258 2018-11-29 2023-11-29       1826\n",
      "3    ABEV       1258 2018-11-29 2023-11-29       1826\n",
      "4    ABNB        747 2020-12-10 2023-11-29       1084\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_existing['Date'] = pd.to_datetime(df_existing['Date']) \n",
    "\n",
    "# 기업별 관측일 통계\n",
    "company_stats = df_existing.groupby('Company').agg({\n",
    "    'Date': ['count', 'min', 'max']\n",
    "}).reset_index()\n",
    "\n",
    "# 컬럼명 재설정 (MultiIndex Flattening)\n",
    "company_stats.columns = ['Company', 'Obs_Count', 'Start_Date', 'End_Date']\n",
    "\n",
    "# 날짜 객체끼리의 연산이므로 Timedelta가 생성되고 .dt.days 사용 가능\n",
    "company_stats['Days_Span'] = (company_stats['End_Date'] - company_stats['Start_Date']).dt.days\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"기업별 관측일 수 통계\")\n",
    "print(\"=\" * 60)\n",
    "print(company_stats[['Obs_Count', 'Days_Span']].describe())\n",
    "print(f\"\\n기대 관측일 수 (5년): ~1,258일 (252 거래일 x 5년)\")\n",
    "\n",
    "# 데이터 확인 (상위 5개)\n",
    "print(company_stats.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T04:49:28.355058Z",
     "iopub.status.busy": "2026-01-12T04:49:28.354984Z",
     "iopub.status.idle": "2026-01-12T04:49:28.357552Z",
     "shell.execute_reply": "2026-01-12T04:49:28.357227Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "기업 분류 결과\n",
      "============================================================\n",
      "동일 기간 비교 가능 기업: 471개 (95.9%)\n",
      "개별 분석 대상 기업: 20개 (4.1%)\n",
      "\n",
      "기준: 최대 관측일(1258)의 80% = 1006일 이상\n"
     ]
    }
   ],
   "source": [
    "# 동일 기간 비교 가능 기업 분류\n",
    "# 기준: 최소 관측일의 80% 이상 보유\n",
    "max_obs = company_stats['Obs_Count'].max()\n",
    "threshold = max_obs * 0.8\n",
    "\n",
    "# 전체 기간 데이터 보유 기업\n",
    "full_period_mask = company_stats['Obs_Count'] >= threshold\n",
    "full_period_companies = company_stats[full_period_mask]['Company'].tolist()\n",
    "partial_period_companies = company_stats[~full_period_mask]['Company'].tolist()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"기업 분류 결과\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"동일 기간 비교 가능 기업: {len(full_period_companies)}개 ({len(full_period_companies)/len(tickers)*100:.1f}%)\")\n",
    "print(f\"개별 분석 대상 기업: {len(partial_period_companies)}개 ({len(partial_period_companies)/len(tickers)*100:.1f}%)\")\n",
    "print(f\"\\n기준: 최대 관측일({max_obs})의 80% = {threshold:.0f}일 이상\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T04:49:28.358531Z",
     "iopub.status.busy": "2026-01-12T04:49:28.358473Z",
     "iopub.status.idle": "2026-01-12T04:49:28.360826Z",
     "shell.execute_reply": "2026-01-12T04:49:28.360525Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "개별 분석 대상 기업 (관측일 적은 순):\n",
      "Company  Obs_Count Start_Date   End_Date\n",
      "    ARM         54 2023-09-14 2023-11-29\n",
      "   KVUE        145 2023-05-04 2023-11-29\n",
      "   GEHC        240 2022-12-15 2023-11-29\n",
      "   MBLY        275 2022-10-26 2023-11-29\n",
      "    HLN        341 2022-07-25 2023-11-29\n",
      "    CEG        469 2022-01-19 2023-11-29\n",
      "     NU        496 2021-12-09 2023-11-29\n",
      "    GFS        525 2021-10-28 2023-11-29\n",
      "   COIN        663 2021-04-14 2023-11-29\n",
      "   CPNG        686 2021-03-11 2023-11-29\n",
      "   RBLX        687 2021-03-10 2023-11-29\n",
      "    SYM        688 2021-03-09 2023-11-29\n",
      "   ABNB        747 2020-12-10 2023-11-29\n",
      "   DASH        748 2020-12-09 2023-11-29\n",
      "   PLTR        797 2020-09-30 2023-11-29\n",
      "   SNOW        807 2020-09-16 2023-11-29\n",
      "   BEKE        830 2020-08-13 2023-11-29\n",
      "     LI        840 2020-07-30 2023-11-29\n",
      "   CARR        932 2020-03-19 2023-11-29\n",
      "   OTIS        932 2020-03-19 2023-11-29\n"
     ]
    }
   ],
   "source": [
    "# 개별 분석 대상 기업 상세\n",
    "partial_stats = company_stats[~full_period_mask].sort_values('Obs_Count')\n",
    "\n",
    "print(\"개별 분석 대상 기업 (관측일 적은 순):\")\n",
    "print(partial_stats[['Company', 'Obs_Count', 'Start_Date', 'End_Date']].head(30).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 OHLC 이상치 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T04:49:28.361789Z",
     "iopub.status.busy": "2026-01-12T04:49:28.361736Z",
     "iopub.status.idle": "2026-01-12T04:49:28.426645Z",
     "shell.execute_reply": "2026-01-12T04:49:28.426264Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "OHLC 이상치 검증 결과\n",
      "============================================================\n",
      "총 이상치: 42건\n",
      "\n",
      "유형별 집계:\n",
      "Type\n",
      "Open/Close out of H/L range    30\n",
      "Extreme daily change (>50%)    12\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# OHLC 이상치 검증 함수\n",
    "def validate_ohlc(df):\n",
    "    \"\"\"OHLC 데이터 이상치 검증\"\"\"\n",
    "    anomalies = []\n",
    "    \n",
    "    # 1. 0값 또는 음수 검출\n",
    "    for col in ['Open', 'High', 'Low', 'Close']:\n",
    "        zero_or_neg = df[df[col] <= 0]\n",
    "        if len(zero_or_neg) > 0:\n",
    "            for _, row in zero_or_neg.iterrows():\n",
    "                anomalies.append({\n",
    "                    'Company': row['Company'],\n",
    "                    'Date': row['Date'],\n",
    "                    'Type': f'{col} <= 0',\n",
    "                    'Value': row[col]\n",
    "                })\n",
    "    \n",
    "    # 2. High < Low 역전\n",
    "    inverted = df[df['High'] < df['Low']]\n",
    "    for _, row in inverted.iterrows():\n",
    "        anomalies.append({\n",
    "            'Company': row['Company'],\n",
    "            'Date': row['Date'],\n",
    "            'Type': 'High < Low',\n",
    "            'Value': f\"H:{row['High']:.2f}, L:{row['Low']:.2f}\"\n",
    "        })\n",
    "    \n",
    "    # 3. Open/Close가 High/Low 범위 밖\n",
    "    out_of_range = df[(df['Open'] > df['High']) | (df['Open'] < df['Low']) |\n",
    "                      (df['Close'] > df['High']) | (df['Close'] < df['Low'])]\n",
    "    for _, row in out_of_range.iterrows():\n",
    "        anomalies.append({\n",
    "            'Company': row['Company'],\n",
    "            'Date': row['Date'],\n",
    "            'Type': 'Open/Close out of H/L range',\n",
    "            'Value': f\"O:{row['Open']:.2f}, H:{row['High']:.2f}, L:{row['Low']:.2f}, C:{row['Close']:.2f}\"\n",
    "        })\n",
    "    \n",
    "    # 4. 극단적 일간 변동 (>50%)\n",
    "    df_temp = df.copy()\n",
    "    df_temp['Daily_Change'] = df_temp.groupby('Company')['Close'].pct_change().abs()\n",
    "    extreme_change = df_temp[df_temp['Daily_Change'] > 0.5]\n",
    "    for _, row in extreme_change.iterrows():\n",
    "        anomalies.append({\n",
    "            'Company': row['Company'],\n",
    "            'Date': row['Date'],\n",
    "            'Type': 'Extreme daily change (>50%)',\n",
    "            'Value': f\"{row['Daily_Change']*100:.1f}%\"\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(anomalies)\n",
    "\n",
    "# 검증 실행\n",
    "anomaly_df = validate_ohlc(df_existing)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"OHLC 이상치 검증 결과\")\n",
    "print(\"=\" * 60)\n",
    "if len(anomaly_df) == 0:\n",
    "    print(\"이상치 없음\")\n",
    "else:\n",
    "    print(f\"총 이상치: {len(anomaly_df)}건\")\n",
    "    print(f\"\\n유형별 집계:\")\n",
    "    print(anomaly_df['Type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T04:49:28.427720Z",
     "iopub.status.busy": "2026-01-12T04:49:28.427662Z",
     "iopub.status.idle": "2026-01-12T04:49:28.429784Z",
     "shell.execute_reply": "2026-01-12T04:49:28.429477Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "이상치 상세 :\n",
      "Company       Date                        Type                                  Value\n",
      "      A 2023-11-29 Open/Close out of H/L range O:125.59, H:127.42, L:125.66, C:127.01\n",
      "    AEM 2023-11-29 Open/Close out of H/L range     O:53.69, H:53.48, L:52.65, C:52.96\n",
      "    BMO 2023-11-29 Open/Close out of H/L range     O:79.86, H:80.82, L:79.87, C:80.63\n",
      "   BSBR 2023-11-29 Open/Close out of H/L range         O:6.20, H:6.28, L:6.21, C:6.26\n",
      "     DB 2023-11-29 Open/Close out of H/L range     O:12.27, H:12.41, L:12.28, C:12.38\n",
      "    ELP 2019-06-06 Open/Close out of H/L range         O:4.01, H:4.02, L:3.98, C:3.98\n",
      "    ENB 2023-11-29 Open/Close out of H/L range     O:34.35, H:34.63, L:34.38, C:34.54\n",
      "   FERG 2020-04-27 Open/Close out of H/L range     O:61.30, H:61.30, L:61.30, C:61.30\n",
      "    FNV 2023-11-29 Open/Close out of H/L range O:117.50, H:117.40, L:114.88, C:115.07\n",
      "    GIB 2023-11-29 Open/Close out of H/L range  O:101.35, H:101.03, L:99.86, C:100.04\n",
      "     HD 2023-11-29 Open/Close out of H/L range O:314.06, H:313.89, L:311.93, C:313.02\n",
      "    HEI 2023-11-29 Open/Close out of H/L range O:171.01, H:170.90, L:168.15, C:169.12\n",
      "   HSBC 2023-11-29 Open/Close out of H/L range     O:37.90, H:38.08, L:37.92, C:37.99\n",
      "   HUBS 2023-11-29 Open/Close out of H/L range O:482.01, H:493.14, L:482.26, C:492.49\n",
      "   INTC 2023-11-29 Open/Close out of H/L range     O:44.60, H:45.30, L:44.61, C:45.06\n",
      "   ITUB 2023-11-29 Open/Close out of H/L range         O:6.33, H:6.40, L:6.34, C:6.37\n",
      "    LMT 2023-11-29 Open/Close out of H/L range O:449.54, H:449.43, L:443.91, C:446.30\n",
      "    MTB 2023-11-29 Open/Close out of H/L range O:126.19, H:129.41, L:126.29, C:128.04\n",
      "    NVS 2018-12-27 Open/Close out of H/L range     O:61.35, H:62.27, L:60.79, C:62.27\n",
      "   SHEL 2021-05-05 Open/Close out of H/L range     O:35.44, H:36.15, L:35.79, C:36.09\n",
      "   SHEL 2023-01-24 Open/Close out of H/L range     O:49.28, H:56.14, L:54.08, C:55.74\n",
      "     SQ 2023-11-29 Open/Close out of H/L range     O:63.58, H:65.11, L:63.66, C:64.72\n",
      "    TMO 2023-11-29 Open/Close out of H/L range O:489.89, H:495.80, L:489.94, C:492.93\n",
      "    TRI 2023-11-29 Open/Close out of H/L range O:140.43, H:140.36, L:138.57, C:139.27\n",
      "    TTD 2023-11-29 Open/Close out of H/L range     O:68.72, H:72.34, L:69.92, C:70.37\n",
      "     TU 2019-05-21 Open/Close out of H/L range     O:14.81, H:15.00, L:14.81, C:15.00\n",
      "     TU 2023-11-29 Open/Close out of H/L range     O:17.80, H:17.77, L:17.64, C:17.66\n",
      "   VALE 2019-10-21 Open/Close out of H/L range         O:7.78, H:7.87, L:7.76, C:7.87\n",
      "   WDAY 2023-11-29 Open/Close out of H/L range O:235.00, H:267.49, L:252.56, C:265.88\n",
      "    WMT 2023-11-29 Open/Close out of H/L range O:158.77, H:158.67, L:155.61, C:155.93\n",
      "   BEKE 2022-03-16 Extreme daily change (>50%)                                  64.3%\n",
      "   BNTX 2020-03-17 Extreme daily change (>50%)                                  66.5%\n",
      "    CVE 2020-03-09 Extreme daily change (>50%)                                  52.5%\n",
      "  FCNCA 2023-03-27 Extreme daily change (>50%)                                  53.7%\n",
      "    OXY 2020-03-09 Extreme daily change (>50%)                                  52.0%\n",
      "    PCG 2019-01-14 Extreme daily change (>50%)                                  52.4%\n",
      "    PCG 2019-01-24 Extreme daily change (>50%)                                  74.6%\n",
      "    PDD 2022-03-16 Extreme daily change (>50%)                                  56.1%\n",
      "   SNAP 2022-02-04 Extreme daily change (>50%)                                  58.8%\n",
      "    SYM 2022-06-08 Extreme daily change (>50%)                                 120.5%\n",
      "    SYM 2023-07-31 Extreme daily change (>50%)                                  50.6%\n",
      "   TRGP 2020-03-09 Extreme daily change (>50%)                                  52.9%\n"
     ]
    }
   ],
   "source": [
    "# 이상치 상세\n",
    "if len(anomaly_df) > 0:\n",
    "    print(\"\\n이상치 상세 :\")\n",
    "    print(anomaly_df.head(42).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 데이터 정제 (Data Cleaning)\n",
    "\n",
    "**목적**: OHLC 논리 오류 수정 및 극단 변화 플래그 추가\n",
    "\n",
    "**처리 항목**:\n",
    "1. OHLC 범위 오류 수정 (Open/Close out of H/L range)\n",
    "2. 극단적 일간 변동(>50%) 플래그 추가 (삭제하지 않음)\n",
    "3. 부동소수점 오차 허용 (tolerance=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T04:49:28.430844Z",
     "iopub.status.busy": "2026-01-12T04:49:28.430764Z",
     "iopub.status.idle": "2026-01-12T04:49:28.435705Z",
     "shell.execute_reply": "2026-01-12T04:49:28.435361Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 정제 함수 정의 완료\n"
     ]
    }
   ],
   "source": [
    "def clean_ohlc_violations(df, tolerance=0.01):\n",
    "    \"\"\"\n",
    "    OHLC 범위 오류 수정\n",
    "    \n",
    "    Args:\n",
    "        df: 원본 데이터프레임\n",
    "        tolerance: 부동소수점 오차 허용값 (기본 0.01 = 1센트)\n",
    "    \n",
    "    Returns:\n",
    "        df_cleaned: 정제된 데이터프레임\n",
    "        cleaning_log: 수정 내역 로그\n",
    "    \"\"\"\n",
    "    df_cleaned = df.copy()\n",
    "    cleaning_log = []\n",
    "    \n",
    "    # 1. Open > High 수정\n",
    "    mask_open_high = df_cleaned['Open'] > (df_cleaned['High'] + tolerance)\n",
    "    if mask_open_high.sum() > 0:\n",
    "        for idx in df_cleaned[mask_open_high].index:\n",
    "            row = df_cleaned.loc[idx]\n",
    "            cleaning_log.append({\n",
    "                'Index': idx,\n",
    "                'Company': row['Company'],\n",
    "                'Date': row['Date'],\n",
    "                'Type': 'Open > High',\n",
    "                'Original_High': row['High'],\n",
    "                'Original_Open': row['Open'],\n",
    "                'Corrected_High': row['Open']\n",
    "            })\n",
    "        df_cleaned.loc[mask_open_high, 'High'] = df_cleaned.loc[mask_open_high, 'Open']\n",
    "    \n",
    "    # 2. Open < Low 수정\n",
    "    mask_open_low = df_cleaned['Open'] < (df_cleaned['Low'] - tolerance)\n",
    "    if mask_open_low.sum() > 0:\n",
    "        for idx in df_cleaned[mask_open_low].index:\n",
    "            row = df_cleaned.loc[idx]\n",
    "            cleaning_log.append({\n",
    "                'Index': idx,\n",
    "                'Company': row['Company'],\n",
    "                'Date': row['Date'],\n",
    "                'Type': 'Open < Low',\n",
    "                'Original_Low': row['Low'],\n",
    "                'Original_Open': row['Open'],\n",
    "                'Corrected_Low': row['Open']\n",
    "            })\n",
    "        df_cleaned.loc[mask_open_low, 'Low'] = df_cleaned.loc[mask_open_low, 'Open']\n",
    "    \n",
    "    # 3. Close > High 수정\n",
    "    mask_close_high = df_cleaned['Close'] > (df_cleaned['High'] + tolerance)\n",
    "    if mask_close_high.sum() > 0:\n",
    "        for idx in df_cleaned[mask_close_high].index:\n",
    "            row = df_cleaned.loc[idx]\n",
    "            cleaning_log.append({\n",
    "                'Index': idx,\n",
    "                'Company': row['Company'],\n",
    "                'Date': row['Date'],\n",
    "                'Type': 'Close > High',\n",
    "                'Original_High': row['High'],\n",
    "                'Original_Close': row['Close'],\n",
    "                'Corrected_High': row['Close']\n",
    "            })\n",
    "        df_cleaned.loc[mask_close_high, 'High'] = df_cleaned.loc[mask_close_high, 'Close']\n",
    "    \n",
    "    # 4. Close < Low 수정\n",
    "    mask_close_low = df_cleaned['Close'] < (df_cleaned['Low'] - tolerance)\n",
    "    if mask_close_low.sum() > 0:\n",
    "        for idx in df_cleaned[mask_close_low].index:\n",
    "            row = df_cleaned.loc[idx]\n",
    "            cleaning_log.append({\n",
    "                'Index': idx,\n",
    "                'Company': row['Company'],\n",
    "                'Date': row['Date'],\n",
    "                'Type': 'Close < Low',\n",
    "                'Original_Low': row['Low'],\n",
    "                'Original_Close': row['Close'],\n",
    "                'Corrected_Low': row['Close']\n",
    "            })\n",
    "        df_cleaned.loc[mask_close_low, 'Low'] = df_cleaned.loc[mask_close_low, 'Close']\n",
    "    \n",
    "    cleaning_log_df = pd.DataFrame(cleaning_log)\n",
    "    \n",
    "    return df_cleaned, cleaning_log_df\n",
    "\n",
    "\n",
    "def add_extreme_change_flag(df, threshold=0.5):\n",
    "    \"\"\"\n",
    "    극단적 일간 변동 플래그 추가 (데이터 삭제하지 않음)\n",
    "    \n",
    "    Args:\n",
    "        df: 데이터프레임\n",
    "        threshold: 극단 변화 기준 (기본 0.5 = 50%)\n",
    "    \n",
    "    Returns:\n",
    "        df: 플래그가 추가된 데이터프레임\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 기업별로 일간 수익률 계산 (임시)\n",
    "    df['Daily_Change_Temp'] = df.groupby('Company')['Close'].pct_change().abs()\n",
    "    \n",
    "    # 극단 변화 플래그\n",
    "    df['Is_Extreme_Change'] = df['Daily_Change_Temp'] > threshold\n",
    "    \n",
    "    # 임시 컬럼 제거\n",
    "    df = df.drop(columns=['Daily_Change_Temp'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def validate_ohlc_with_tolerance(df, tolerance=0.01):\n",
    "    \"\"\"\n",
    "    부동소수점 오차를 허용한 OHLC 검증\n",
    "    \n",
    "    Args:\n",
    "        df: 데이터프레임\n",
    "        tolerance: 허용 오차 (기본 0.01)\n",
    "    \n",
    "    Returns:\n",
    "        anomaly_df: 이상치 데이터프레임\n",
    "    \"\"\"\n",
    "    anomalies = []\n",
    "    \n",
    "    # 1. 0값 또는 음수 검출\n",
    "    for col in ['Open', 'High', 'Low', 'Close']:\n",
    "        zero_or_neg = df[df[col] <= 0]\n",
    "        if len(zero_or_neg) > 0:\n",
    "            for _, row in zero_or_neg.iterrows():\n",
    "                anomalies.append({\n",
    "                    'Company': row['Company'],\n",
    "                    'Date': row['Date'],\n",
    "                    'Type': f'{col} <= 0',\n",
    "                    'Value': row[col]\n",
    "                })\n",
    "    \n",
    "    # 2. High < Low 역전 (tolerance 적용)\n",
    "    inverted = df[df['High'] < (df['Low'] - tolerance)]\n",
    "    for _, row in inverted.iterrows():\n",
    "        anomalies.append({\n",
    "            'Company': row['Company'],\n",
    "            'Date': row['Date'],\n",
    "            'Type': 'High < Low',\n",
    "            'Value': f\"H:{row['High']:.2f}, L:{row['Low']:.2f}\"\n",
    "        })\n",
    "    \n",
    "    # 3. Open/Close가 High/Low 범위 밖 (tolerance 적용)\n",
    "    out_of_range = df[\n",
    "        (df['Open'] > df['High'] + tolerance) | \n",
    "        (df['Open'] < df['Low'] - tolerance) |\n",
    "        (df['Close'] > df['High'] + tolerance) | \n",
    "        (df['Close'] < df['Low'] - tolerance)\n",
    "    ]\n",
    "    for _, row in out_of_range.iterrows():\n",
    "        anomalies.append({\n",
    "            'Company': row['Company'],\n",
    "            'Date': row['Date'],\n",
    "            'Type': 'Open/Close out of H/L range',\n",
    "            'Value': f\"O:{row['Open']:.2f}, H:{row['High']:.2f}, L:{row['Low']:.2f}, C:{row['Close']:.2f}\"\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(anomalies)\n",
    "\n",
    "print(\"데이터 정제 함수 정의 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T04:49:28.436598Z",
     "iopub.status.busy": "2026-01-12T04:49:28.436542Z",
     "iopub.status.idle": "2026-01-12T04:49:28.457302Z",
     "shell.execute_reply": "2026-01-12T04:49:28.457014Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OHLC 범위 오류 수정\n",
      "수정된 건수: 23건\n",
      "\n",
      "수정 유형별 집계:\n",
      "Type\n",
      "Open < Low     14\n",
      "Open > High     9\n",
      "Name: count, dtype: int64\n",
      "\n",
      "수정 상세:\n",
      " Index Company       Date        Type  Original_High  Original_Open  Corrected_High  Original_Low  Corrected_Low\n",
      " 18358     AEM 2023-11-29 Open > High      53.479900      53.689999       53.689999           NaN            NaN\n",
      "226963     FNV 2023-11-29 Open > High     117.400002     117.500000      117.500000           NaN            NaN\n",
      "235276     GIB 2023-11-29 Open > High     101.030899     101.349998      101.349998           NaN            NaN\n",
      "254146      HD 2023-11-29 Open > High     313.890015     314.059998      314.059998           NaN            NaN\n",
      "256662     HEI 2023-11-29 Open > High     170.899506     171.009995      171.009995           NaN            NaN\n",
      "320888     LMT 2023-11-29 Open > High     449.429993     449.540009      449.540009           NaN            NaN\n",
      "529029     TRI 2023-11-29 Open > High     140.360001     140.429993      140.429993           NaN            NaN\n",
      "544125      TU 2023-11-29 Open > High      17.775000      17.799999       17.799999           NaN            NaN\n",
      "587960     WMT 2023-11-29 Open > High     158.669998     158.770004      158.770004           NaN            NaN\n",
      "  1257       A 2023-11-29  Open < Low            NaN     125.589996             NaN    125.660004     125.589996\n"
     ]
    }
   ],
   "source": [
    "# 1. OHLC 범위 오류 수정\n",
    "print(\"OHLC 범위 오류 수정\")\n",
    "\n",
    "df_cleaned, cleaning_log = clean_ohlc_violations(df_existing, tolerance=0.01)\n",
    "\n",
    "print(f\"수정된 건수: {len(cleaning_log)}건\")\n",
    "\n",
    "if len(cleaning_log) > 0:\n",
    "    print(f\"\\n수정 유형별 집계:\")\n",
    "    print(cleaning_log['Type'].value_counts())\n",
    "    print(f\"\\n수정 상세:\")\n",
    "    print(cleaning_log.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T04:49:28.458509Z",
     "iopub.status.busy": "2026-01-12T04:49:28.458447Z",
     "iopub.status.idle": "2026-01-12T04:49:28.544718Z",
     "shell.execute_reply": "2026-01-12T04:49:28.544382Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "플래그 추가 완료!\n",
      "극단 변화 건수: 12건 (삭제하지 않고 보존)\n",
      "\n",
      "극단 변화 기업 (상위 10건):\n",
      "Company       Date      Close\n",
      "   BEKE 2022-03-16  14.731359\n",
      "   BNTX 2020-03-17  65.729401\n",
      "    CVE 2020-03-09   2.652992\n",
      "  FCNCA 2023-03-27 894.600281\n",
      "    OXY 2020-03-09  12.256660\n",
      "    PCG 2019-01-14   8.380000\n",
      "    PCG 2019-01-24  13.950000\n",
      "    PDD 2022-03-16  42.619999\n",
      "   SNAP 2022-02-04  38.910000\n",
      "    SYM 2022-06-08  20.070000\n"
     ]
    }
   ],
   "source": [
    "# 2. 극단적 변화 플래그 추가\n",
    "\n",
    "df_cleaned = add_extreme_change_flag(df_cleaned, threshold=0.5)\n",
    "\n",
    "extreme_count = df_cleaned['Is_Extreme_Change'].sum()\n",
    "print(f\"\\n플래그 추가 완료!\")\n",
    "print(f\"극단 변화 건수: {extreme_count}건 (삭제하지 않고 보존)\")\n",
    "\n",
    "if extreme_count > 0:\n",
    "    print(f\"\\n극단 변화 기업 (상위 10건):\")\n",
    "    extreme_cases = df_cleaned[df_cleaned['Is_Extreme_Change']]\n",
    "    print(extreme_cases[['Company', 'Date', 'Close']].head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T04:49:28.545728Z",
     "iopub.status.busy": "2026-01-12T04:49:28.545655Z",
     "iopub.status.idle": "2026-01-12T04:49:28.554522Z",
     "shell.execute_reply": "2026-01-12T04:49:28.554150Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "정제 후 OHLC 재검증 (tolerance=0.01)\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "재검증 결과:\n",
      "OHLC 이상치 없음\n"
     ]
    }
   ],
   "source": [
    "# 3. 정제 후 재검증 (tolerance 적용)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"정제 후 OHLC 재검증 (tolerance=0.01)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "anomaly_after = validate_ohlc_with_tolerance(df_cleaned, tolerance=0.01)\n",
    "\n",
    "print(f\"\\n재검증 결과:\")\n",
    "if len(anomaly_after) == 0:\n",
    "    print(\"OHLC 이상치 없음\")\n",
    "else:\n",
    "    print(f\"   남은 이상치: {len(anomaly_after)}건\")\n",
    "    print(f\"\\n유형별 집계:\")\n",
    "    print(anomaly_after['Type'].value_counts())\n",
    "    print(f\"\\n상세:\")\n",
    "    print(anomaly_after.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T04:49:28.555481Z",
     "iopub.status.busy": "2026-01-12T04:49:28.555416Z",
     "iopub.status.idle": "2026-01-12T04:49:28.558502Z",
     "shell.execute_reply": "2026-01-12T04:49:28.558258Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "데이터 정제 비교\n",
      "============================================================\n",
      "\n",
      "항목                             Before          After           개선        \n",
      "----------------------------------------------------------------------\n",
      "OHLC 범위 오류                     30              0               ✅\n",
      "극단 변화 (>50%)                   12 (오류)         12 (플래그)        ✅\n",
      "전체 데이터 행 수                     602962          602962          ✅\n",
      "\n",
      "============================================================\n",
      "✅ 데이터 정제 완료!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# 4. Before/After 비교 리포트\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"데이터 정제 비교\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\n{'항목':<30} {'Before':<15} {'After':<15} {'개선':<10}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# OHLC 범위 오류\n",
    "before_ohlc = len(anomaly_df[anomaly_df['Type'] == 'Open/Close out of H/L range'])\n",
    "# Handle empty DataFrame case\n",
    "if len(anomaly_after) == 0 or 'Type' not in anomaly_after.columns:\n",
    "    after_ohlc = 0\n",
    "else:\n",
    "    after_ohlc = len(anomaly_after[anomaly_after['Type'] == 'Open/Close out of H/L range'])\n",
    "print(f\"{'OHLC 범위 오류':<30} {before_ohlc:<15} {after_ohlc:<15} {'✅' if after_ohlc == 0 else '⚠️'}\")\n",
    "\n",
    "# 극단 변화 (플래그로 전환)\n",
    "before_extreme = len(anomaly_df[anomaly_df['Type'] == 'Extreme daily change (>50%)'])\n",
    "after_extreme = df_cleaned['Is_Extreme_Change'].sum()\n",
    "print(f\"{'극단 변화 (>50%)':<30} {f'{before_extreme} (오류)':<15} {f'{after_extreme} (플래그)':<15} {'✅'}\")\n",
    "\n",
    "# 전체 데이터\n",
    "print(f\"{'전체 데이터 행 수':<30} {len(df_existing):<15} {len(df_cleaned):<15} {'✅'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"데이터 정제 완료!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T04:49:28.559591Z",
     "iopub.status.busy": "2026-01-12T04:49:28.559520Z",
     "iopub.status.idle": "2026-01-12T04:49:28.582710Z",
     "shell.execute_reply": "2026-01-12T04:49:28.582428Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "정제 로그 저장: /Users/yu_seok/Documents/workspace/nbCamp/Project/Yahoo Finance/Data_set/QA/ohlc_cleaning_log.csv\n",
      "df_existing을 정제된 데이터로 업데이트 완료\n"
     ]
    }
   ],
   "source": [
    "# 5. 정제 로그 저장\n",
    "if len(cleaning_log) > 0:\n",
    "    cleaning_log.to_csv(QA_DIR / 'ohlc_cleaning_log.csv', index=False)\n",
    "    print(f\"\\n정제 로그 저장: {QA_DIR / 'ohlc_cleaning_log.csv'}\")\n",
    "\n",
    "# 기존 데이터를 정제된 데이터로 교체\n",
    "df_existing = df_cleaned.copy()\n",
    "print(f\"df_existing을 정제된 데이터로 업데이트 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Dividends & Stock Splits 이벤트 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T04:49:28.583802Z",
     "iopub.status.busy": "2026-01-12T04:49:28.583746Z",
     "iopub.status.idle": "2026-01-12T04:49:28.588370Z",
     "shell.execute_reply": "2026-01-12T04:49:28.588078Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "배당 (Dividends) 이벤트 분석\n",
      "============================================================\n",
      "배당 지급 기업 수: 385개 (78.4%)\n",
      "총 배당 이벤트 수: 6857건\n",
      "\n",
      "기업별 배당 횟수 (상위 10):\n",
      "Company\n",
      "ITUB    80\n",
      "BBD     69\n",
      "O       60\n",
      "COP     28\n",
      "EOG     26\n",
      "PCAR    25\n",
      "CME     25\n",
      "BSBR    22\n",
      "NOC     21\n",
      "FAST    21\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 배당 이벤트 분석\n",
    "dividend_events = df_existing[df_existing['Dividends'] > 0].copy()\n",
    "dividend_companies = dividend_events['Company'].unique()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"배당 (Dividends) 이벤트 분석\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"배당 지급 기업 수: {len(dividend_companies)}개 ({len(dividend_companies)/len(tickers)*100:.1f}%)\")\n",
    "print(f\"총 배당 이벤트 수: {len(dividend_events)}건\")\n",
    "\n",
    "# 기업별 배당 횟수\n",
    "dividend_freq = dividend_events.groupby('Company').size().sort_values(ascending=False)\n",
    "print(f\"\\n기업별 배당 횟수 (상위 10):\")\n",
    "print(dividend_freq.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T04:49:28.589293Z",
     "iopub.status.busy": "2026-01-12T04:49:28.589237Z",
     "iopub.status.idle": "2026-01-12T04:49:28.592368Z",
     "shell.execute_reply": "2026-01-12T04:49:28.592031Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "주식 분할 분석\n",
      "============================================================\n",
      "주식 분할 기업 수: 61개 (12.4%)\n",
      "총 분할 수: 71건\n",
      "\n",
      "주식 분할 상세:\n",
      "Company       Date  Stock Splits\n",
      "   AAPL 2020-08-31        4.0000\n",
      "   AMZN 2022-06-06       20.0000\n",
      "   ANET 2021-11-18        4.0000\n",
      "    APH 2021-03-05        2.0000\n",
      "    BBD 2019-04-01        1.2000\n",
      "    BDX 2022-04-01        1.0250\n",
      "    BHP 2022-06-02        1.1210\n",
      "     BN 2020-04-02        1.5000\n",
      "     BN 2022-12-12        1.2370\n",
      "     CM 2022-05-16        2.0000\n",
      "    CNC 2019-02-07        2.0000\n",
      "    CNQ 2022-08-22        1.0210\n",
      "     CP 2021-05-14        5.0000\n",
      "   CPRT 2022-11-04        2.0000\n",
      "   CPRT 2023-08-22        2.0000\n",
      "   CSGP 2021-06-28       10.0000\n",
      "    CSX 2021-06-29        3.0000\n",
      "     DD 2019-04-02        1.4870\n",
      "     DD 2019-06-03        0.4725\n",
      "   DELL 2018-12-28        1.8060\n",
      "   DELL 2021-11-02        1.9730\n",
      "    DHR 2023-10-02        1.1280\n",
      "    DTE 2021-07-01        1.1750\n",
      "   DXCM 2022-06-13        4.0000\n",
      "    ELP 2021-03-18       10.0000\n",
      "    ELP 2021-04-28        0.2000\n",
      "     EW 2020-06-01        3.0000\n",
      "    EXC 2022-02-02        1.4020\n",
      "   FAST 2019-05-23        2.0000\n",
      "   FTNT 2022-06-23        5.0000\n",
      "    FTV 2020-10-09        1.1950\n",
      "     GE 2019-02-26        1.0400\n",
      "     GE 2021-08-02        0.1250\n",
      "     GE 2023-01-04        1.2810\n",
      "  GOOGL 2022-07-18       20.0000\n",
      "    GSK 2022-07-19        0.8000\n",
      "    GSK 2022-07-22        1.2260\n",
      "    HDB 2019-09-26        2.0000\n",
      "    IBM 2021-11-04        1.0460\n",
      "   ISRG 2021-10-05        3.0000\n",
      "   ITUB 2021-10-04        1.2130\n",
      "   MCHP 2021-10-13        2.0000\n",
      "    MRK 2021-06-03        1.0480\n",
      "   NDAQ 2022-08-29        3.0000\n",
      "    NEE 2020-10-27        4.0000\n",
      "   NTES 2020-10-02        5.0000\n",
      "   NVDA 2021-07-20        4.0000\n",
      "    NVO 2023-09-20        2.0000\n",
      "    NVS 2019-04-09        1.1160\n",
      "    NWG 2022-08-30        0.9280\n",
      "      O 2021-11-15        1.0320\n",
      "   ODFL 2020-03-25        1.5000\n",
      "   PANW 2022-09-14        3.0000\n",
      "   PCAR 2023-02-08        1.5000\n",
      "    PFE 2020-11-17        1.0540\n",
      "    PUK 2021-09-20        1.0310\n",
      "    RJF 2021-09-22        1.5000\n",
      "    ROL 2018-12-11        1.5000\n",
      "    ROL 2020-12-11        1.5000\n",
      "    RTX 2020-04-03        1.5890\n",
      "   SHOP 2022-06-29       10.0000\n",
      "    SHW 2021-04-01        3.0000\n",
      "    SRE 2023-08-22        2.0000\n",
      "      T 2022-04-11        1.3240\n",
      "    TRI 2023-06-23        0.9630\n",
      "   TSLA 2020-08-31        5.0000\n",
      "   TSLA 2022-08-25        3.0000\n",
      "     TT 2020-03-02        1.2890\n",
      "    TTD 2021-06-17       10.0000\n",
      "     TU 2020-03-18        2.0000\n",
      "    ZBH 2022-03-01        1.0300\n"
     ]
    }
   ],
   "source": [
    "# 주식 분할 이벤트 분석\n",
    "split_events = df_existing[df_existing['Stock Splits'] > 0].copy()\n",
    "split_companies = split_events['Company'].unique()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"주식 분할 분석\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"주식 분할 기업 수: {len(split_companies)}개 ({len(split_companies)/len(tickers)*100:.1f}%)\")\n",
    "print(f\"총 분할 수: {len(split_events)}건\")\n",
    "\n",
    "if len(split_events) > 0:\n",
    "    print(f\"\\n주식 분할 상세:\")\n",
    "    print(split_events[['Company', 'Date', 'Stock Splits']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T04:49:28.593259Z",
     "iopub.status.busy": "2026-01-12T04:49:28.593205Z",
     "iopub.status.idle": "2026-01-12T04:49:28.747077Z",
     "shell.execute_reply": "2026-01-12T04:49:28.746686Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "배당, 주식 분할 보유 기업 수: 399개"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 이벤트(배당, 주식 분할) 기업 목록 저장용 데이터프레임 생성\n",
    "event_summary = []\n",
    "\n",
    "for company in tickers:\n",
    "    div_count = len(dividend_events[dividend_events['Company'] == company])\n",
    "    split_count = len(split_events[split_events['Company'] == company])\n",
    "    \n",
    "    if div_count > 0 or split_count > 0:\n",
    "        event_summary.append({\n",
    "            'Company': company,\n",
    "            'Dividend_Count': div_count,\n",
    "            'Split_Count': split_count,\n",
    "            'Has_Dividend': div_count > 0,\n",
    "            'Has_Split': split_count > 0\n",
    "        })\n",
    "\n",
    "event_df = pd.DataFrame(event_summary)\n",
    "print(f\"\\n배당, 주식 분할 보유 기업 수: {len(event_df)}개\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 수익률 결측치 처리 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T04:49:28.748151Z",
     "iopub.status.busy": "2026-01-12T04:49:28.748083Z",
     "iopub.status.idle": "2026-01-12T04:49:28.786901Z",
     "shell.execute_reply": "2026-01-12T04:49:28.786462Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "수익률 결측치 처리 검증\n",
      "============================================================\n",
      "첫 거래일 Daily_Return = NaN: 0개 \n",
      "첫 거래일 Daily_Return = 0: 4개 검토 필요\n",
      "첫 거래일 Daily_Return = 기타값: 487개 검토 필요\n"
     ]
    }
   ],
   "source": [
    "# 각 기업 첫 거래일의 Daily_Return 검증\n",
    "first_day_returns = df_existing.groupby('Company').first()['Daily_Return']\n",
    "\n",
    "# NaN인 경우 (정상)\n",
    "nan_first_day = first_day_returns.isna().sum()\n",
    "# 0인 경우 (의심)\n",
    "zero_first_day = (first_day_returns == 0).sum()\n",
    "# 값이 있는 경우 (오류 가능성)\n",
    "has_value_first_day = first_day_returns.notna().sum() - zero_first_day\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"수익률 결측치 처리 검증\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"첫 거래일 Daily_Return = NaN: {nan_first_day}개 {'정상' if nan_first_day == len(tickers) else ''}\")\n",
    "print(f\"첫 거래일 Daily_Return = 0: {zero_first_day}개 {'검토 필요' if zero_first_day > 0 else ''}\")\n",
    "print(f\"첫 거래일 Daily_Return = 기타값: {has_value_first_day}개 {'검토 필요' if has_value_first_day > 0 else ''}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T04:49:28.788014Z",
     "iopub.status.busy": "2026-01-12T04:49:28.787959Z",
     "iopub.status.idle": "2026-01-12T04:49:28.816093Z",
     "shell.execute_reply": "2026-01-12T04:49:28.815714Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Daily_Return=0 but Close changed: 0건\n",
      "부적절한 0 대입 없음\n"
     ]
    }
   ],
   "source": [
    "# Daily_Return이 0인데 Close 변화가 있는 경우 (오류)\n",
    "df_check = df_existing.copy()\n",
    "df_check['Prev_Close_Calc'] = df_check.groupby('Company')['Close'].shift(1)\n",
    "df_check['Close_Changed'] = (df_check['Close'] != df_check['Prev_Close_Calc']) & df_check['Prev_Close_Calc'].notna()\n",
    "\n",
    "suspicious_zeros = df_check[(df_check['Daily_Return'] == 0) & df_check['Close_Changed']]\n",
    "\n",
    "print(f\"\\nDaily_Return=0 but Close changed: {len(suspicious_zeros)}건\")\n",
    "if len(suspicious_zeros) > 0:\n",
    "    print(\"부적절한 0 대입 의심\")\n",
    "    print(suspicious_zeros[['Company', 'Date', 'Close', 'Prev_Close_Calc', 'Daily_Return']].head(10))\n",
    "else:\n",
    "    print(\"부적절한 0 대입 없음\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T04:49:28.817194Z",
     "iopub.status.busy": "2026-01-12T04:49:28.817135Z",
     "iopub.status.idle": "2026-01-12T04:49:29.023311Z",
     "shell.execute_reply": "2026-01-12T04:49:29.022962Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5일 이상 연속 결측 기업: 0개"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 연속 NaN 패턴 (거래 정지 등)\n",
    "def find_consecutive_nans(group):\n",
    "    \"\"\"연속 NaN 구간 찾기\"\"\"\n",
    "    is_nan = group['Daily_Return'].isna()\n",
    "    # 첫날 NaN 제외\n",
    "    is_nan.iloc[0] = False\n",
    "    \n",
    "    consecutive = (is_nan != is_nan.shift()).cumsum()\n",
    "    nan_groups = group[is_nan].groupby(consecutive[is_nan]).size()\n",
    "    \n",
    "    if len(nan_groups) > 0 and nan_groups.max() > 5:  # 5일 이상 연속 NaN\n",
    "        return nan_groups.max()\n",
    "    return 0\n",
    "\n",
    "consecutive_nans = df_existing.groupby('Company').apply(find_consecutive_nans)\n",
    "companies_with_gaps = consecutive_nans[consecutive_nans > 0]\n",
    "\n",
    "print(f\"\\n5일 이상 연속 결측 기업: {len(companies_with_gaps)}개\")\n",
    "if len(companies_with_gaps) > 0:\n",
    "    print(companies_with_gaps.sort_values(ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 3. 티커 메타데이터 수집 (섹터/산업 최신화)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T04:49:29.024546Z",
     "iopub.status.busy": "2026-01-12T04:49:29.024470Z",
     "iopub.status.idle": "2026-01-12T04:49:29.027666Z",
     "shell.execute_reply": "2026-01-12T04:49:29.027337Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "메타데이터 수집 함수 정의 완료\n"
     ]
    }
   ],
   "source": [
    "def fetch_ticker_metadata(ticker_list, batch_size=50, max_retries=3):\n",
    "    \"\"\"\n",
    "    yfinance를 사용하여 티커별 섹터/산업 정보 수집\n",
    "    \n",
    "    Args:\n",
    "        ticker_list: 티커 목록\n",
    "        batch_size: 배치 크기 (API 부하 방지)\n",
    "        max_retries: 최대 재시도 횟수\n",
    "    \n",
    "    Returns:\n",
    "        dict: {ticker: {'Sector': ..., 'Industry': ...}}\n",
    "    \"\"\"\n",
    "    metadata = {}\n",
    "    failed_tickers = []\n",
    "    \n",
    "    # 배치 분할\n",
    "    chunks = [ticker_list[i:i + batch_size] for i in range(0, len(ticker_list), batch_size)]\n",
    "    \n",
    "    for chunk in tqdm(chunks, desc=\"Fetching Metadata\"):\n",
    "        tickers_str = ' '.join(chunk)\n",
    "        \n",
    "        try:\n",
    "            tickers_obj = yf.Tickers(tickers_str)\n",
    "            \n",
    "            for symbol in chunk:\n",
    "                for attempt in range(max_retries):\n",
    "                    try:\n",
    "                        info = tickers_obj.tickers[symbol].info\n",
    "                        \n",
    "                        sector = info.get('sector', 'Unknown')\n",
    "                        industry = info.get('industry', 'Unknown')\n",
    "                        \n",
    "                        # Unknown이면 개별 호출 재시도\n",
    "                        if sector == 'Unknown':\n",
    "                            single = yf.Ticker(symbol)\n",
    "                            sector = single.info.get('sector', 'Unknown')\n",
    "                            industry = single.info.get('industry', 'Unknown')\n",
    "                        \n",
    "                        metadata[symbol] = {\n",
    "                            'Sector': sector,\n",
    "                            'Industry': industry\n",
    "                        }\n",
    "                        break\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        if attempt == max_retries - 1:\n",
    "                            failed_tickers.append(symbol)\n",
    "                            metadata[symbol] = {'Sector': 'Error', 'Industry': 'Error'}\n",
    "                        time.sleep(0.5)\n",
    "                \n",
    "                time.sleep(0.05)  # Rate limit 방지\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Chunk Error: {e}\")\n",
    "            for symbol in chunk:\n",
    "                failed_tickers.append(symbol)\n",
    "                metadata[symbol] = {'Sector': 'Error', 'Industry': 'Error'}\n",
    "    \n",
    "    return metadata, failed_tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T04:49:29.028713Z",
     "iopub.status.busy": "2026-01-12T04:49:29.028646Z",
     "iopub.status.idle": "2026-01-12T04:53:29.810024Z",
     "shell.execute_reply": "2026-01-12T04:53:29.807832Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "섹터/산업 메타데이터 수집 시작...\n",
      "대상 티커 수: 491개\n",
      "예상 소요 시간: ~0.8분\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Fetching Metadata:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: ANSS\"}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: ANSS\"}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Fetching Metadata:  10%|█         | 1/10 [00:25<03:53, 25.93s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Fetching Metadata:  20%|██        | 2/10 [00:50<03:20, 25.11s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Fetching Metadata:  30%|███       | 3/10 [01:14<02:51, 24.55s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Fetching Metadata:  40%|████      | 4/10 [01:38<02:25, 24.24s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: HES\"}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: HES\"}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Fetching Metadata:  50%|█████     | 5/10 [02:03<02:03, 24.68s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Fetching Metadata:  60%|██████    | 6/10 [02:27<01:37, 24.47s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Fetching Metadata:  70%|███████   | 7/10 [02:51<01:13, 24.42s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Fetching Metadata:  80%|████████  | 8/10 [03:16<00:48, 24.33s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Fetching Metadata:  90%|█████████ | 9/10 [03:41<00:24, 24.54s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Fetching Metadata: 100%|██████████| 10/10 [04:00<00:00, 23.03s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Fetching Metadata: 100%|██████████| 10/10 [04:00<00:00, 24.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "수집 완료!\n",
      "성공: 491개\n",
      "실패: 0개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 메타데이터 수집 실행\n",
    "print(f\"대상 티커 수: {len(tickers)}개\")\n",
    "print(f\"예상 소요 시간: ~{len(tickers) * 0.1 / 60:.1f}분\\n\")\n",
    "\n",
    "metadata, failed_tickers = fetch_ticker_metadata(tickers)\n",
    "\n",
    "print(f\"\\n수집 완료\")\n",
    "print(f\"성공: {len(metadata) - len(failed_tickers)}개\")\n",
    "print(f\"실패: {len(failed_tickers)}개\")\n",
    "\n",
    "if failed_tickers:\n",
    "    print(f\"\\n실패 티커: {failed_tickers[:20]}{'...' if len(failed_tickers) > 20 else ''}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T04:53:29.813561Z",
     "iopub.status.busy": "2026-01-12T04:53:29.813180Z",
     "iopub.status.idle": "2026-01-12T04:53:29.821580Z",
     "shell.execute_reply": "2026-01-12T04:53:29.820672Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "최신 섹터 분포\n",
      "============================================================\n",
      "Sector_New\n",
      "Financial Services        82\n",
      "Technology                77\n",
      "Healthcare                57\n",
      "Industrials               56\n",
      "Consumer Cyclical         45\n",
      "Energy                    38\n",
      "Consumer Defensive        31\n",
      "Communication Services    27\n",
      "Basic Materials           26\n",
      "Utilities                 24\n",
      "Real Estate               19\n",
      "Unknown                    9\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 메타데이터 데이터프레임 변환\n",
    "metadata_df = pd.DataFrame.from_dict(metadata, orient='index').reset_index()\n",
    "metadata_df.columns = ['Company', 'Sector_New', 'Industry_New']\n",
    "\n",
    "# 섹터별 분포 확인\n",
    "print(\"=\" * 60)\n",
    "print(\"최신 섹터 분포\")\n",
    "print(\"=\" * 60)\n",
    "print(metadata_df['Sector_New'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 4. 신규 가격 데이터 수집 (2023-11-30 ~ 현재)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T04:53:29.824294Z",
     "iopub.status.busy": "2026-01-12T04:53:29.824082Z",
     "iopub.status.idle": "2026-01-12T04:53:29.830262Z",
     "shell.execute_reply": "2026-01-12T04:53:29.829921Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가격 데이터 수집 함수 정의 완료\n"
     ]
    }
   ],
   "source": [
    "def fetch_price_data(ticker_list, start_date, end_date, batch_size=50):\n",
    "    \"\"\"\n",
    "    yfinance를 사용하여 가격 데이터 수집\n",
    "    \n",
    "    Args:\n",
    "        ticker_list: 티커 목록\n",
    "        start_date: 시작일 (YYYY-MM-DD)\n",
    "        end_date: 종료일 (YYYY-MM-DD)\n",
    "        batch_size: 배치 크기\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: OHLCV 데이터\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    failed_tickers = []\n",
    "    \n",
    "    # 배치 분할\n",
    "    chunks = [ticker_list[i:i + batch_size] for i in range(0, len(ticker_list), batch_size)]\n",
    "    \n",
    "    for chunk in tqdm(chunks, desc=\"Fetching Price Data\"):\n",
    "        tickers_str = ' '.join(chunk)\n",
    "        \n",
    "        try:\n",
    "            # 배치 다운로드\n",
    "            data = yf.download(\n",
    "                tickers_str,\n",
    "                start=start_date,\n",
    "                end=end_date,\n",
    "                group_by='ticker',\n",
    "                auto_adjust=True,  # Adjusted Close 사용\n",
    "                progress=False\n",
    "            )\n",
    "            \n",
    "            if len(chunk) == 1:\n",
    "                # 단일 티커인 경우 구조가 다름\n",
    "                symbol = chunk[0]\n",
    "                if not data.empty:\n",
    "                    df_ticker = data.copy()\n",
    "                    df_ticker['Company'] = symbol\n",
    "                    df_ticker = df_ticker.reset_index()\n",
    "                    all_data.append(df_ticker)\n",
    "                else:\n",
    "                    failed_tickers.append(symbol)\n",
    "            else:\n",
    "                # 멀티 티커\n",
    "                for symbol in chunk:\n",
    "                    try:\n",
    "                        if symbol in data.columns.get_level_values(0):\n",
    "                            df_ticker = data[symbol].copy()\n",
    "                            df_ticker['Company'] = symbol\n",
    "                            df_ticker = df_ticker.reset_index()\n",
    "                            \n",
    "                            # NaN 행 제거\n",
    "                            df_ticker = df_ticker.dropna(subset=['Close'])\n",
    "                            \n",
    "                            if not df_ticker.empty:\n",
    "                                all_data.append(df_ticker)\n",
    "                            else:\n",
    "                                failed_tickers.append(symbol)\n",
    "                        else:\n",
    "                            failed_tickers.append(symbol)\n",
    "                    except Exception:\n",
    "                        failed_tickers.append(symbol)\n",
    "            \n",
    "            time.sleep(0.1)  # Rate limit 방지\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Batch Error: {e}\")\n",
    "            failed_tickers.extend(chunk)\n",
    "    \n",
    "    # 데이터 병합\n",
    "    if all_data:\n",
    "        df_combined = pd.concat(all_data, ignore_index=True)\n",
    "        \n",
    "        # 컬럼명 정리\n",
    "        df_combined.columns = [col.replace(' ', '_') if isinstance(col, str) else col for col in df_combined.columns]\n",
    "        \n",
    "        # Date 컬럼 처리\n",
    "        if 'Date' in df_combined.columns:\n",
    "            df_combined['Date'] = pd.to_datetime(df_combined['Date']).dt.tz_localize(None)\n",
    "        \n",
    "        return df_combined, failed_tickers\n",
    "    else:\n",
    "        return pd.DataFrame(), failed_tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T04:53:29.831495Z",
     "iopub.status.busy": "2026-01-12T04:53:29.831423Z",
     "iopub.status.idle": "2026-01-12T04:53:29.834068Z",
     "shell.execute_reply": "2026-01-12T04:53:29.833769Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기존 데이터 마지막 날짜: 2023-11-29\n",
      "신규 데이터 수집 기간: 2023-11-30 ~ 2026-01-12\n"
     ]
    }
   ],
   "source": [
    "# 수집 기간 설정\n",
    "existing_max_date = df_existing['Date'].max()\n",
    "start_date = (existing_max_date + timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "end_date = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "print(f\"기존 데이터 마지막 날짜: {existing_max_date.strftime('%Y-%m-%d')}\")\n",
    "print(f\"신규 데이터 수집 기간: {start_date} ~ {end_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T04:53:29.835256Z",
     "iopub.status.busy": "2026-01-12T04:53:29.835189Z",
     "iopub.status.idle": "2026-01-12T04:54:06.922671Z",
     "shell.execute_reply": "2026-01-12T04:54:06.922276Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대상 티커 수: 491개\n",
      "예상 소요 시간: ~1.2분\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Fetching Price Data:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Error 404: {\"quoteSummary\":{\"result\":null,\"error\":{\"code\":\"Not Found\",\"description\":\"Quote not found for symbol: ANSS\"}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$ANSS: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2 Failed downloads:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "['AFL']: OperationalError('database is locked')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "['ANSS']: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Fetching Price Data:  10%|█         | 1/10 [00:04<00:38,  4.26s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$BGNE: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "['BGNE']: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Fetching Price Data:  20%|██        | 2/10 [00:07<00:31,  3.94s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$DFS: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "['DFS']: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Fetching Price Data:  30%|███       | 3/10 [00:11<00:27,  3.97s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Fetching Price Data:  40%|████      | 4/10 [00:15<00:22,  3.73s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$HES: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "['HES']: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Fetching Price Data:  50%|█████     | 5/10 [00:19<00:18,  3.78s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Fetching Price Data:  60%|██████    | 6/10 [00:22<00:14,  3.63s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$ORAN: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "['ORAN']: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Fetching Price Data:  70%|███████   | 7/10 [00:26<00:11,  3.70s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$PXD: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$SGEN: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2 Failed downloads:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "['PXD', 'SGEN']: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Fetching Price Data:  80%|████████  | 8/10 [00:30<00:07,  3.72s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$SPLK: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "$SQ: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2 Failed downloads:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "['SPLK', 'SQ']: possibly delisted; no timezone found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Fetching Price Data:  90%|█████████ | 9/10 [00:34<00:03,  3.77s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Fetching Price Data: 100%|██████████| 10/10 [00:37<00:00,  3.54s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Fetching Price Data: 100%|██████████| 10/10 [00:37<00:00,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "수집 완료!\n",
      "신규 데이터 Shape: (254439, 7)\n",
      "수집 실패 티커: 10개\n",
      "\n",
      "실패 티커: ['AFL', 'ANSS', 'BGNE', 'DFS', 'HES', 'ORAN', 'PXD', 'SGEN', 'SPLK', 'SQ']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 가격 데이터 수집 실행\n",
    "print(f\"대상 티커 수: {len(tickers)}개\")\n",
    "\n",
    "df_new, price_failed_tickers = fetch_price_data(tickers, start_date, end_date)\n",
    "\n",
    "print(f\"\\n수집 완료\")\n",
    "print(f\"신규 데이터 Shape: {df_new.shape}\")\n",
    "print(f\"수집 실패 티커: {len(price_failed_tickers)}개\")\n",
    "\n",
    "if price_failed_tickers:\n",
    "    print(f\"\\n실패 티커: {price_failed_tickers[:20]}{'...' if len(price_failed_tickers) > 20 else ''}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T04:54:06.923971Z",
     "iopub.status.busy": "2026-01-12T04:54:06.923896Z",
     "iopub.status.idle": "2026-01-12T04:54:06.930688Z",
     "shell.execute_reply": "2026-01-12T04:54:06.930378Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "신규 데이터 기간: 2023-11-30 00:00:00 ~ 2026-01-09 00:00:00\n",
      "신규 데이터 기업 수: 481\n",
      "\n",
      "컬럼 목록: ['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Company']\n"
     ]
    }
   ],
   "source": [
    "# 신규 데이터 확인\n",
    "if not df_new.empty:\n",
    "    print(f\"\\n신규 데이터 기간: {df_new['Date'].min()} ~ {df_new['Date'].max()}\")\n",
    "    print(f\"신규 데이터 기업 수: {df_new['Company'].nunique()}\")\n",
    "    print(f\"\\n컬럼 목록: {df_new.columns.tolist()}\")\n",
    "    df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 5. 신규 데이터 품질 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T04:54:06.932074Z",
     "iopub.status.busy": "2026-01-12T04:54:06.931988Z",
     "iopub.status.idle": "2026-01-12T04:54:06.961053Z",
     "shell.execute_reply": "2026-01-12T04:54:06.960633Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "신규 데이터 OHLC 검증\n",
      "============================================================\n",
      "총 이상치: 4건\n",
      "Type\n",
      "Open/Close out of H/L range    4\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 신규 데이터 OHLC 검증\n",
    "if not df_new.empty:\n",
    "    # 컬럼명 매핑 (yfinance 출력 형식에 맞춤)\n",
    "    col_mapping = {\n",
    "        'Adj_Close': 'Close',  # auto_adjust=True면 이미 조정됨\n",
    "    }\n",
    "    df_new_check = df_new.rename(columns=col_mapping)\n",
    "    \n",
    "    new_anomalies = validate_ohlc(df_new_check)\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"신규 데이터 OHLC 검증\")\n",
    "    print(\"=\" * 60)\n",
    "    if len(new_anomalies) == 0:\n",
    "        print(\"이상치 없음\")\n",
    "    else:\n",
    "        print(f\"총 이상치: {len(new_anomalies)}건\")\n",
    "        print(new_anomalies['Type'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 6. 데이터 정합성 검증 & 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T04:54:06.962288Z",
     "iopub.status.busy": "2026-01-12T04:54:06.962201Z",
     "iopub.status.idle": "2026-01-12T04:54:06.965160Z",
     "shell.execute_reply": "2026-01-12T04:54:06.964760Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정합성 검증 함수 정의 완료\n"
     ]
    }
   ],
   "source": [
    "def validate_price_continuity(df_old, df_new, threshold=0.05):\n",
    "    \"\"\"\n",
    "    기존 데이터와 신규 데이터의 연결 시점 가격 점프 검증\n",
    "    \n",
    "    Args:\n",
    "        df_old: 기존 데이터\n",
    "        df_new: 신규 데이터\n",
    "        threshold: 허용 변동률 (기본 5%)\n",
    "    \n",
    "    Returns:\n",
    "        dict: 검증 결과\n",
    "    \"\"\"\n",
    "    warnings_list = []\n",
    "    \n",
    "    # 기존 데이터의 마지막 종가\n",
    "    last_prices = df_old.groupby('Company').last()[['Date', 'Close']].reset_index()\n",
    "    last_prices.columns = ['Company', 'Old_Date', 'Old_Close']\n",
    "    \n",
    "    # 신규 데이터의 첫 종가\n",
    "    first_prices = df_new.groupby('Company').first()[['Date', 'Close']].reset_index()\n",
    "    first_prices.columns = ['Company', 'New_Date', 'New_Close']\n",
    "    \n",
    "    # 병합\n",
    "    merged = pd.merge(last_prices, first_prices, on='Company', how='inner')\n",
    "    \n",
    "    # 변동률 계산\n",
    "    merged['Price_Change'] = (merged['New_Close'] - merged['Old_Close']) / merged['Old_Close']\n",
    "    merged['Price_Change_Abs'] = merged['Price_Change'].abs()\n",
    "    \n",
    "    # 임계값 초과 검출\n",
    "    suspicious = merged[merged['Price_Change_Abs'] > threshold]\n",
    "    \n",
    "    for _, row in suspicious.iterrows():\n",
    "        warnings_list.append({\n",
    "            'Company': row['Company'],\n",
    "            'Old_Date': row['Old_Date'],\n",
    "            'Old_Close': row['Old_Close'],\n",
    "            'New_Date': row['New_Date'],\n",
    "            'New_Close': row['New_Close'],\n",
    "            'Change_Pct': row['Price_Change'] * 100\n",
    "        })\n",
    "    \n",
    "    return {\n",
    "        'total_companies': len(merged),\n",
    "        'warnings_count': len(warnings_list),\n",
    "        'warnings': pd.DataFrame(warnings_list) if warnings_list else pd.DataFrame()\n",
    "    }\n",
    "\n",
    "print(\"정합성 검증 함수 정의 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T04:54:06.966219Z",
     "iopub.status.busy": "2026-01-12T04:54:06.966137Z",
     "iopub.status.idle": "2026-01-12T04:54:07.018501Z",
     "shell.execute_reply": "2026-01-12T04:54:07.018223Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "가격 연속성 검증 결과\n",
      "============================================================\n",
      "검증 대상 기업: 481개\n",
      "5% 이상 가격 점프: 198개\n",
      "\n",
      "가격 점프 상세 (상위 10건):\n",
      "Company   Old_Date   Old_Close   New_Date  New_Close  Change_Pct\n",
      "    CMG 2023-11-29 2194.449951 2023-11-30  44.044998  -97.992891\n",
      "   AVGO 2023-11-29  940.530029 2023-11-30  90.110336  -90.419196\n",
      "   LRCX 2023-11-29  720.604980 2023-11-30  70.036964  -90.280810\n",
      "   NVDA 2023-11-29  480.734985 2023-11-30  46.739845  -90.277420\n",
      "   NFLX 2023-11-29  476.940002 2023-11-30  47.396999  -90.062272\n",
      "     IX 2023-11-29   91.070000 2023-11-30  17.343882  -80.955439\n",
      "   TSCO 2023-11-29  203.500000 2023-11-30  39.275684  -80.699909\n",
      "   SONY 2023-11-29   86.305000 2023-11-30  17.026321  -80.271918\n",
      "    NOW 2023-11-29  681.080017 2023-11-30 137.147995  -79.863160\n",
      "   CTAS 2023-11-29  549.890015 2023-11-30 136.092163  -75.251021\n"
     ]
    }
   ],
   "source": [
    "# 정합성 검증 실행\n",
    "if not df_new.empty:\n",
    "    continuity_result = validate_price_continuity(df_existing, df_new, threshold=0.05)\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"가격 연속성 검증 결과\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"검증 대상 기업: {continuity_result['total_companies']}개\")\n",
    "    print(f\"5% 이상 가격 점프: {continuity_result['warnings_count']}개\")\n",
    "    \n",
    "    if continuity_result['warnings_count'] > 0:\n",
    "        print(\"\\n가격 점프 상세 (상위 10건):\")\n",
    "        print(continuity_result['warnings'].sort_values('Change_Pct', key=abs, ascending=False).head(10).to_string(index=False))\n",
    "    else:\n",
    "        print(\"\\n모든 기업 정상\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T04:54:07.019626Z",
     "iopub.status.busy": "2026-01-12T04:54:07.019556Z",
     "iopub.status.idle": "2026-01-12T04:54:07.029773Z",
     "shell.execute_reply": "2026-01-12T04:54:07.029357Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정리된 신규 데이터 Shape: (254439, 9)\n",
      "컬럼: ['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Company', 'Dividends', 'Stock Splits']\n"
     ]
    }
   ],
   "source": [
    "# 데이터 병합 준비\n",
    "if not df_new.empty:\n",
    "    # 신규 데이터 컬럼 정리\n",
    "    df_new_clean = df_new.copy()\n",
    "    \n",
    "    # 필요한 컬럼만 선택 (기존 데이터 구조와 맞춤)\n",
    "    base_columns = ['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Company']\n",
    "    \n",
    "    # 컬럼 존재 확인 및 선택\n",
    "    available_cols = [col for col in base_columns if col in df_new_clean.columns]\n",
    "    df_new_clean = df_new_clean[available_cols].copy()\n",
    "    \n",
    "    # Dividends, Stock Splits 추가 (없으면 0)\n",
    "    if 'Dividends' not in df_new_clean.columns:\n",
    "        df_new_clean['Dividends'] = 0.0\n",
    "    if 'Stock Splits' not in df_new_clean.columns:\n",
    "        df_new_clean['Stock Splits'] = 0.0\n",
    "    \n",
    "    print(f\"정리된 신규 데이터 Shape: {df_new_clean.shape}\")\n",
    "    print(f\"컬럼: {df_new_clean.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T04:54:07.030826Z",
     "iopub.status.busy": "2026-01-12T04:54:07.030751Z",
     "iopub.status.idle": "2026-01-12T04:54:07.082802Z",
     "shell.execute_reply": "2026-01-12T04:54:07.082408Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "메타데이터 매핑 완료\n",
      "        Date        Open        High         Low       Close     Volume  \\\n",
      "0 2023-11-30  125.889922  126.332501  124.876903  125.693222  2442900.0   \n",
      "1 2023-12-01  125.240799  126.883268  124.424487  126.666893  1729600.0   \n",
      "2 2023-12-04  126.293171  127.089816  125.762072  126.755424  1543200.0   \n",
      "3 2023-12-05  125.703043  126.509532  123.696672  125.771889  1933600.0   \n",
      "4 2023-12-06  126.381690  127.620914  125.811250  126.784935  1816800.0   \n",
      "\n",
      "  Company  Dividends  Stock Splits      Sector                Industry  \n",
      "0       A        0.0           0.0  Healthcare  Diagnostics & Research  \n",
      "1       A        0.0           0.0  Healthcare  Diagnostics & Research  \n",
      "2       A        0.0           0.0  Healthcare  Diagnostics & Research  \n",
      "3       A        0.0           0.0  Healthcare  Diagnostics & Research  \n",
      "4       A        0.0           0.0  Healthcare  Diagnostics & Research  \n"
     ]
    }
   ],
   "source": [
    "# 메타데이터 매핑\n",
    "if not df_new.empty:\n",
    "    # 신규 데이터에 섹터/산업 매핑\n",
    "    df_new_clean = df_new_clean.merge(metadata_df, on='Company', how='left')\n",
    "    df_new_clean['Sector'] = df_new_clean['Sector_New'].fillna('Unknown')\n",
    "    df_new_clean['Industry'] = df_new_clean['Industry_New'].fillna('Unknown')\n",
    "    df_new_clean = df_new_clean.drop(columns=['Sector_New', 'Industry_New'], errors='ignore')\n",
    "    \n",
    "    print(f\"메타데이터 매핑 완료\")\n",
    "    print(df_new_clean.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T04:54:07.083912Z",
     "iopub.status.busy": "2026-01-12T04:54:07.083847Z",
     "iopub.status.idle": "2026-01-12T04:54:07.553256Z",
     "shell.execute_reply": "2026-01-12T04:54:07.552795Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "병합 완료!\n",
      "병합 데이터 Shape: (857401, 11)\n",
      "기간: 2018-11-29 00:00:00 ~ 2026-01-09 00:00:00\n",
      "기업 수: 491\n"
     ]
    }
   ],
   "source": [
    "# 기존 데이터 + 신규 데이터 병합\n",
    "if not df_new.empty:\n",
    "    # 기존 데이터에서 파생변수 컬럼 제거 후 재계산\n",
    "    base_cols = ['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits', 'Company', 'Sector']\n",
    "    df_existing_base = df_existing[[col for col in base_cols if col in df_existing.columns]].copy()\n",
    "    \n",
    "    # 기존 데이터 섹터 업데이트\n",
    "    df_existing_base = df_existing_base.drop(columns=['Sector'], errors='ignore')\n",
    "    df_existing_base = df_existing_base.merge(metadata_df[['Company', 'Sector_New']], on='Company', how='left')\n",
    "    df_existing_base['Sector'] = df_existing_base['Sector_New'].fillna('Unknown')\n",
    "    df_existing_base = df_existing_base.drop(columns=['Sector_New'], errors='ignore')\n",
    "    \n",
    "    # Industry 추가\n",
    "    if 'Industry_New' in metadata_df.columns:\n",
    "        df_existing_base = df_existing_base.merge(metadata_df[['Company', 'Industry_New']], on='Company', how='left')\n",
    "        df_existing_base['Industry'] = df_existing_base['Industry_New'].fillna('Unknown')\n",
    "        df_existing_base = df_existing_base.drop(columns=['Industry_New'], errors='ignore')\n",
    "    \n",
    "    # 병합\n",
    "    df_combined = pd.concat([df_existing_base, df_new_clean], ignore_index=True)\n",
    "    \n",
    "    # 중복 제거 (Company, Date 기준)\n",
    "    df_combined = df_combined.drop_duplicates(subset=['Company', 'Date'], keep='last')\n",
    "    \n",
    "    # 정렬\n",
    "    df_combined = df_combined.sort_values(['Company', 'Date']).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"\\n병합 완료!\")\n",
    "    print(f\"병합 데이터 Shape: {df_combined.shape}\")\n",
    "    print(f\"기간: {df_combined['Date'].min()} ~ {df_combined['Date'].max()}\")\n",
    "    print(f\"기업 수: {df_combined['Company'].nunique()}\")\n",
    "else:\n",
    "    # 신규 데이터가 없으면 기존 데이터만 사용\n",
    "    df_combined = df_existing.copy()\n",
    "    print(\"신규 데이터 없음. 기존 데이터만 사용.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 7. 파생변수 계산\n",
    "\n",
    "### 계산 대상\n",
    "- **기존**: Daily_Return, Cum_Return, MA_5/20/60, Volatility_20d, MDD, Vol_Ratio, Vol_Z_Score, Gap_Pct\n",
    "- **신규**: RSI_14, BB_Upper, BB_Middle, BB_Lower, BB_Width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T04:54:07.554482Z",
     "iopub.status.busy": "2026-01-12T04:54:07.554401Z",
     "iopub.status.idle": "2026-01-12T04:54:07.557063Z",
     "shell.execute_reply": "2026-01-12T04:54:07.556760Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSI, Bollinger Bands 함수 정의 완료\n"
     ]
    }
   ],
   "source": [
    "def calculate_rsi(series, period=14):\n",
    "    \"\"\"\n",
    "    RSI (Relative Strength Index) 계산\n",
    "    \n",
    "    Args:\n",
    "        series: 종가 시리즈\n",
    "        period: 기간 (기본 14일)\n",
    "    \n",
    "    Returns:\n",
    "        RSI 시리즈\n",
    "    \"\"\"\n",
    "    delta = series.diff()\n",
    "    \n",
    "    gain = delta.where(delta > 0, 0)\n",
    "    loss = (-delta).where(delta < 0, 0)\n",
    "    \n",
    "    avg_gain = gain.rolling(window=period, min_periods=period).mean()\n",
    "    avg_loss = loss.rolling(window=period, min_periods=period).mean()\n",
    "    \n",
    "    rs = avg_gain / avg_loss\n",
    "    rsi = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    return rsi\n",
    "\n",
    "\n",
    "def calculate_bollinger_bands(series, period=20, std_dev=2):\n",
    "    \"\"\"\n",
    "    볼린저 밴드 계산\n",
    "    \n",
    "    Args:\n",
    "        series: 종가 시리즈\n",
    "        period: 이동평균 기간 (기본 20일)\n",
    "        std_dev: 표준편차 배수 (기본 2)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: BB_Upper, BB_Middle, BB_Lower, BB_Width\n",
    "    \"\"\"\n",
    "    middle = series.rolling(window=period).mean()\n",
    "    std = series.rolling(window=period).std()\n",
    "    \n",
    "    upper = middle + (std * std_dev)\n",
    "    lower = middle - (std * std_dev)\n",
    "    width = (upper - lower) / middle * 100  # 백분율\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'BB_Upper': upper,\n",
    "        'BB_Middle': middle,\n",
    "        'BB_Lower': lower,\n",
    "        'BB_Width': width\n",
    "    })\n",
    "\n",
    "print(\"RSI, Bollinger Bands 함수 정의 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T04:54:07.558357Z",
     "iopub.status.busy": "2026-01-12T04:54:07.558290Z",
     "iopub.status.idle": "2026-01-12T04:54:07.562136Z",
     "shell.execute_reply": "2026-01-12T04:54:07.561837Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 파생변수 계산 함수 정의 완료 (데이터 누수 방지 개선)\n"
     ]
    }
   ],
   "source": [
    "def calculate_all_features(df):\n",
    "    \"\"\"\n",
    "    모든 파생변수 일괄 계산 (데이터 누수 방지 개선 버전)\n",
    "    \n",
    "    Args:\n",
    "        df: 기본 OHLCV 데이터\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: 파생변수가 추가된 데이터\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df = df.sort_values(['Company', 'Date']).reset_index(drop=True)\n",
    "        \n",
    "    # 1. 일간 수익률 (기업별로 독립 계산, 첫날은 NaN 유지)\n",
    "    df['Daily_Return'] = df.groupby('Company')['Close'].pct_change()\n",
    "    \n",
    "    # 2. 누적 수익률 (기업별 독립 계산)\n",
    "    df['Cum_Return'] = df.groupby('Company')['Close'].transform(\n",
    "        lambda x: (x / x.iloc[0]) - 1\n",
    "    )\n",
    "    \n",
    "    # 3. 이동평균선 (기업별 독립 계산)\n",
    "    for window in [5, 20, 60]:\n",
    "        df[f'MA_{window}'] = df.groupby('Company')['Close'].transform(\n",
    "            lambda x: x.rolling(window).mean()\n",
    "        )\n",
    "    \n",
    "    # 4. 변동성 (20일, 기업별 독립 계산)\n",
    "    df['Volatility_20d'] = df.groupby('Company')['Daily_Return'].transform(\n",
    "        lambda x: x.rolling(20).std()\n",
    "    )\n",
    "    \n",
    "    # 5. MDD (Maximum Drawdown, 기업별 독립 계산)\n",
    "    df['Cum_Max'] = df.groupby('Company')['Close'].transform(\n",
    "        lambda x: x.expanding().max()\n",
    "    )\n",
    "    df['Drawdown'] = (df['Close'] - df['Cum_Max']) / df['Cum_Max']\n",
    "    df['MDD'] = df.groupby('Company')['Drawdown'].transform(\n",
    "        lambda x: x.expanding().min()\n",
    "    )\n",
    "    \n",
    "    # 6. 거래량 지표 (기업별 독립 계산)\n",
    "    df['Vol_MA_20'] = df.groupby('Company')['Volume'].transform(\n",
    "        lambda x: x.rolling(20).mean()\n",
    "    )\n",
    "    df['Vol_Ratio'] = df['Volume'] / df['Vol_MA_20']\n",
    "    df['Vol_Std_20'] = df.groupby('Company')['Volume'].transform(\n",
    "        lambda x: x.rolling(20).std()\n",
    "    )\n",
    "    df['Vol_Z_Score'] = (df['Volume'] - df['Vol_MA_20']) / df['Vol_Std_20']\n",
    "    \n",
    "    # 7. 갭 분석 (기업별 독립 계산)\n",
    "    df['Prev_Close'] = df.groupby('Company')['Close'].shift(1)\n",
    "    df['Gap'] = df['Open'] - df['Prev_Close']\n",
    "    df['Gap_Pct'] = (df['Open'] / df['Prev_Close']) - 1\n",
    "    \n",
    "    # 8. RSI (14일, 기업별 독립 계산)\n",
    "    print(\"  - RSI_14 계산 중...\")\n",
    "    df['RSI_14'] = df.groupby('Company')['Close'].transform(\n",
    "        lambda x: calculate_rsi(x, period=14)\n",
    "    )\n",
    "    \n",
    "    # 9. 볼린저 밴드 (기업별 독립 계산)\n",
    "    bb_results = df.groupby('Company')['Close'].apply(\n",
    "        lambda x: calculate_bollinger_bands(x, period=20, std_dev=2)\n",
    "    )\n",
    "    \n",
    "    # 볼린저 밴드 결과 병합\n",
    "    bb_df = bb_results.reset_index()\n",
    "    bb_df = bb_df.drop(columns=['level_1'], errors='ignore')\n",
    "    \n",
    "    # 인덱스 기반 병합을 위해 원본 인덱스 복원\n",
    "    df = df.reset_index(drop=True)\n",
    "    for col in ['BB_Upper', 'BB_Middle', 'BB_Lower', 'BB_Width']:\n",
    "        if col in bb_df.columns:\n",
    "            df[col] = bb_df[col].values\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T04:54:07.563157Z",
     "iopub.status.busy": "2026-01-12T04:54:07.563105Z",
     "iopub.status.idle": "2026-01-12T04:54:08.778257Z",
     "shell.execute_reply": "2026-01-12T04:54:08.777534Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파생변수 계산 중...\n",
      "  - Daily_Return 계산 중... (groupby 적용)\n",
      "  - Cum_Return 계산 중...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - MA_5, MA_20, MA_60 계산 중...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Volatility_20d 계산 중...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - MDD 계산 중...\n",
      "  - 거래량 지표 계산 중...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - 갭 분석 계산 중...\n",
      "  - RSI_14 계산 중...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Bollinger Bands 계산 중...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ 파생변수 계산 완료!\n",
      "   - 모든 계산에 groupby('Company') 적용\n",
      "   - 각 기업의 첫 거래일 Daily_Return = NaN (정상)\n",
      "\n",
      "최종 데이터 Shape: (857401, 32)\n",
      "\n",
      "컬럼 목록:\n",
      "['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits', 'Company', 'Sector', 'Industry', 'Daily_Return', 'Cum_Return', 'MA_5', 'MA_20', 'MA_60', 'Volatility_20d', 'Cum_Max', 'Drawdown', 'MDD', 'Vol_MA_20', 'Vol_Ratio', 'Vol_Std_20', 'Vol_Z_Score', 'Prev_Close', 'Gap', 'Gap_Pct', 'RSI_14', 'BB_Upper', 'BB_Middle', 'BB_Lower', 'BB_Width']\n"
     ]
    }
   ],
   "source": [
    "# 파생변수 계산 실행\n",
    "df_final = calculate_all_features(df_combined)\n",
    "\n",
    "print(f\"\\n최종 데이터 Shape: {df_final.shape}\")\n",
    "print(f\"\\n컬럼 목록:\")\n",
    "print(df_final.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T04:54:08.779976Z",
     "iopub.status.busy": "2026-01-12T04:54:08.779819Z",
     "iopub.status.idle": "2026-01-12T04:54:08.806612Z",
     "shell.execute_reply": "2026-01-12T04:54:08.805900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AAPL 최근 10일 데이터:\n",
      "      Date      Close  Daily_Return    RSI_14   BB_Upper  BB_Middle   BB_Lower  BB_Width\n",
      "2025-12-26 273.399994     -0.001497 36.148319 285.597359 276.944499 268.291640  6.248804\n",
      "2025-12-29 273.760010      0.001317 39.068321 285.406065 276.689999 267.973934  6.300239\n",
      "2025-12-30 273.079987     -0.002484 39.130463 284.496009 276.188998 267.881988  6.015453\n",
      "2025-12-31 271.859985     -0.004468 31.277093 282.524683 275.472498 268.420312  5.120065\n",
      "2026-01-02 271.010010     -0.003127 31.108797 280.836780 274.815498 268.794217  4.382054\n",
      "2026-01-05 267.260010     -0.013837 25.045369 280.395090 274.143498 267.891906  4.560817\n",
      "2026-01-06 262.359985     -0.018334 24.243819 281.129574 273.322498 265.515421  5.712721\n",
      "2026-01-07 260.329987     -0.007737 20.665643 281.870552 272.444496 263.018440  6.919615\n",
      "2026-01-08 259.040009     -0.004955 22.003583 282.422952 271.537497 260.652042  8.017644\n",
      "2026-01-09 259.369995      0.001274 21.935218 282.170982 270.566997 258.963011  8.577532\n"
     ]
    }
   ],
   "source": [
    "# 파생변수 샘플 확인\n",
    "sample_ticker = 'AAPL'\n",
    "sample_data = df_final[df_final['Company'] == sample_ticker].tail(10)\n",
    "\n",
    "print(f\"\\n{sample_ticker} 최근 10일 데이터:\")\n",
    "display_cols = ['Date', 'Close', 'Daily_Return', 'RSI_14', 'BB_Upper', 'BB_Middle', 'BB_Lower', 'BB_Width']\n",
    "print(sample_data[display_cols].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 8. 집계 데이터 재생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T04:54:08.808426Z",
     "iopub.status.busy": "2026-01-12T04:54:08.808344Z",
     "iopub.status.idle": "2026-01-12T04:54:08.915901Z",
     "shell.execute_reply": "2026-01-12T04:54:08.914906Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sector Summary Shape: (20915, 9)\n",
      "기간: 2018-11-29 00:00:00 ~ 2026-01-09 00:00:00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Sector_Return</th>\n",
       "      <th>Sector_Price_Avg</th>\n",
       "      <th>Sector_Vol_Ratio</th>\n",
       "      <th>Sector_Volatility</th>\n",
       "      <th>Sector_MDD</th>\n",
       "      <th>Sector_RSI</th>\n",
       "      <th>Stock_Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-11-29</td>\n",
       "      <td>Basic Materials</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.660312</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-11-29</td>\n",
       "      <td>Communication Services</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.977137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-11-29</td>\n",
       "      <td>Consumer Cyclical</td>\n",
       "      <td>NaN</td>\n",
       "      <td>214.557717</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-11-29</td>\n",
       "      <td>Consumer Defensive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.924028</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-11-29</td>\n",
       "      <td>Energy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.958204</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date                  Sector  Sector_Return  Sector_Price_Avg  \\\n",
       "0 2018-11-29         Basic Materials            NaN         69.660312   \n",
       "1 2018-11-29  Communication Services            NaN         76.977137   \n",
       "2 2018-11-29       Consumer Cyclical            NaN        214.557717   \n",
       "3 2018-11-29      Consumer Defensive            NaN         72.924028   \n",
       "4 2018-11-29                  Energy            NaN         34.958204   \n",
       "\n",
       "   Sector_Vol_Ratio  Sector_Volatility  Sector_MDD  Sector_RSI  Stock_Count  \n",
       "0               NaN                NaN         0.0         NaN           24  \n",
       "1               NaN                NaN         0.0         NaN           25  \n",
       "2               NaN                NaN         0.0         NaN           40  \n",
       "3               NaN                NaN         0.0         NaN           30  \n",
       "4               NaN                NaN         0.0         NaN           38  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sector Summary 재생성\n",
    "df_sector = df_final.groupby(['Date', 'Sector']).agg({\n",
    "    'Daily_Return': 'mean',\n",
    "    'Close': 'mean',\n",
    "    'Vol_Ratio': 'mean',\n",
    "    'Volatility_20d': 'mean',\n",
    "    'MDD': 'mean',\n",
    "    'RSI_14': 'mean',\n",
    "    'Company': 'count'\n",
    "}).reset_index()\n",
    "\n",
    "df_sector = df_sector.rename(columns={\n",
    "    'Daily_Return': 'Sector_Return',\n",
    "    'Close': 'Sector_Price_Avg',\n",
    "    'Vol_Ratio': 'Sector_Vol_Ratio',\n",
    "    'Volatility_20d': 'Sector_Volatility',\n",
    "    'MDD': 'Sector_MDD',\n",
    "    'RSI_14': 'Sector_RSI',\n",
    "    'Company': 'Stock_Count'\n",
    "})\n",
    "\n",
    "print(f\"Sector Summary Shape: {df_sector.shape}\")\n",
    "print(f\"기간: {df_sector['Date'].min()} ~ {df_sector['Date'].max()}\")\n",
    "df_sector.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T04:54:08.917928Z",
     "iopub.status.busy": "2026-01-12T04:54:08.917777Z",
     "iopub.status.idle": "2026-01-12T04:54:10.697196Z",
     "shell.execute_reply": "2026-01-12T04:54:10.696916Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monthly Summary Shape: (41737, 10)\n",
      "기간: 2018-11-30 00:00:00 ~ 2026-01-31 00:00:00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Monthly_Return</th>\n",
       "      <th>Monthly_Range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>2018-11-30</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>68.673458</td>\n",
       "      <td>70.042470</td>\n",
       "      <td>68.673458</td>\n",
       "      <td>69.753235</td>\n",
       "      <td>4905300.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.993510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>70.698073</td>\n",
       "      <td>72.414195</td>\n",
       "      <td>59.986839</td>\n",
       "      <td>65.199600</td>\n",
       "      <td>50474000.0</td>\n",
       "      <td>-6.528206</td>\n",
       "      <td>17.578070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>2019-01-31</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>64.271775</td>\n",
       "      <td>73.753060</td>\n",
       "      <td>59.922551</td>\n",
       "      <td>73.501778</td>\n",
       "      <td>44194500.0</td>\n",
       "      <td>12.733479</td>\n",
       "      <td>21.518791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>2019-02-28</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>73.608101</td>\n",
       "      <td>77.164765</td>\n",
       "      <td>72.255001</td>\n",
       "      <td>76.778175</td>\n",
       "      <td>35941700.0</td>\n",
       "      <td>4.457576</td>\n",
       "      <td>6.670140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>2019-03-31</td>\n",
       "      <td>Healthcare</td>\n",
       "      <td>77.319419</td>\n",
       "      <td>79.513353</td>\n",
       "      <td>74.806536</td>\n",
       "      <td>77.686691</td>\n",
       "      <td>32806600.0</td>\n",
       "      <td>1.183300</td>\n",
       "      <td>6.087497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Company       Date      Sector       Open       High        Low      Close  \\\n",
       "0       A 2018-11-30  Healthcare  68.673458  70.042470  68.673458  69.753235   \n",
       "1       A 2018-12-31  Healthcare  70.698073  72.414195  59.986839  65.199600   \n",
       "2       A 2019-01-31  Healthcare  64.271775  73.753060  59.922551  73.501778   \n",
       "3       A 2019-02-28  Healthcare  73.608101  77.164765  72.255001  76.778175   \n",
       "4       A 2019-03-31  Healthcare  77.319419  79.513353  74.806536  77.686691   \n",
       "\n",
       "       Volume  Monthly_Return  Monthly_Range  \n",
       "0   4905300.0             NaN       1.993510  \n",
       "1  50474000.0       -6.528206      17.578070  \n",
       "2  44194500.0       12.733479      21.518791  \n",
       "3  35941700.0        4.457576       6.670140  \n",
       "4  32806600.0        1.183300       6.087497  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Monthly Summary 재생성\n",
    "df_monthly = df_final[['Company', 'Sector', 'Date', 'Open', 'High', 'Low', 'Close', 'Volume']].copy()\n",
    "df_monthly = df_monthly.set_index('Date').groupby('Company').resample('ME').agg({\n",
    "    'Sector': 'first',\n",
    "    'Open': 'first',\n",
    "    'High': 'max',\n",
    "    'Low': 'min',\n",
    "    'Close': 'last',\n",
    "    'Volume': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# 월간 수익률\n",
    "df_monthly['Monthly_Return'] = df_monthly.groupby('Company')['Close'].pct_change() * 100\n",
    "\n",
    "# 월간 변동폭\n",
    "df_monthly['Monthly_Range'] = (df_monthly['High'] - df_monthly['Low']) / df_monthly['Open'] * 100\n",
    "\n",
    "print(f\"Monthly Summary Shape: {df_monthly.shape}\")\n",
    "print(f\"기간: {df_monthly['Date'].min()} ~ {df_monthly['Date'].max()}\")\n",
    "df_monthly.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 9. 최종 QA 리포트 & 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T04:54:10.698687Z",
     "iopub.status.busy": "2026-01-12T04:54:10.698613Z",
     "iopub.status.idle": "2026-01-12T04:54:10.702958Z",
     "shell.execute_reply": "2026-01-12T04:54:10.702571Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "데이터 품질 검증 리포트\n",
      "============================================================\n",
      "\n",
      "실행 시간: 2026-01-12 13:54:10\n",
      "\n",
      "1. 데이터 기간\n",
      "   2018-11-29 ~ 2026-01-09\n",
      "\n",
      "2. 기업별 관측일 분석\n",
      "   - 전체 기업 수: 491개\n",
      "   - 동일 기간 비교 가능: 471개\n",
      "   - 개별 분석 대상: 20개\n",
      "\n",
      "3. OHLC 이상치\n",
      "   - 발견된 이상치: 42건\n",
      "\n",
      "4. 이벤트 기업\n",
      "   - 배당 지급 기업: 385개\n",
      "   - 주식 분할 기업: 61개\n",
      "\n",
      "5. 신규 데이터\n",
      "   - 추가된 행 수: 254,439개\n",
      "   - 수집 실패 티커: 10개\n",
      "\n",
      "6. 최종 데이터\n",
      "   - 총 행 수: 857,401개\n",
      "   - 총 컬럼 수: 32개\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# QA 요약 리포트 생성\n",
    "qa_summary = {\n",
    "    'execution_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'data_period': {\n",
    "        'start': df_final['Date'].min().strftime('%Y-%m-%d'),\n",
    "        'end': df_final['Date'].max().strftime('%Y-%m-%d')\n",
    "    },\n",
    "    'company_analysis': {\n",
    "        'total_companies': len(tickers),\n",
    "        'full_period_companies': len(full_period_companies),\n",
    "        'partial_period_companies': len(partial_period_companies)\n",
    "    },\n",
    "    'ohlc_anomalies': len(anomaly_df) if 'anomaly_df' in dir() else 0,\n",
    "    'event_companies': {\n",
    "        'dividend_companies': len(dividend_companies),\n",
    "        'split_companies': len(split_companies)\n",
    "    },\n",
    "    'new_data': {\n",
    "        'rows_added': len(df_new) if not df_new.empty else 0,\n",
    "        'failed_tickers': len(price_failed_tickers) if 'price_failed_tickers' in dir() else 0\n",
    "    },\n",
    "    'final_data': {\n",
    "        'total_rows': len(df_final),\n",
    "        'total_columns': len(df_final.columns)\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"데이터 품질 검증 리포트\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\n실행 시간: {qa_summary['execution_time']}\")\n",
    "print(f\"\\n1. 데이터 기간\")\n",
    "print(f\"   {qa_summary['data_period']['start']} ~ {qa_summary['data_period']['end']}\")\n",
    "print(f\"\\n2. 기업별 관측일 분석\")\n",
    "print(f\"   - 전체 기업 수: {qa_summary['company_analysis']['total_companies']}개\")\n",
    "print(f\"   - 동일 기간 비교 가능: {qa_summary['company_analysis']['full_period_companies']}개\")\n",
    "print(f\"   - 개별 분석 대상: {qa_summary['company_analysis']['partial_period_companies']}개\")\n",
    "print(f\"\\n3. OHLC 이상치\")\n",
    "print(f\"   - 발견된 이상치: {qa_summary['ohlc_anomalies']}건\")\n",
    "print(f\"\\n4. 이벤트 기업\")\n",
    "print(f\"   - 배당 지급 기업: {qa_summary['event_companies']['dividend_companies']}개\")\n",
    "print(f\"   - 주식 분할 기업: {qa_summary['event_companies']['split_companies']}개\")\n",
    "print(f\"\\n5. 신규 데이터\")\n",
    "print(f\"   - 추가된 행 수: {qa_summary['new_data']['rows_added']:,}개\")\n",
    "print(f\"   - 수집 실패 티커: {qa_summary['new_data']['failed_tickers']}개\")\n",
    "print(f\"\\n6. 최종 데이터\")\n",
    "print(f\"   - 총 행 수: {qa_summary['final_data']['total_rows']:,}개\")\n",
    "print(f\"   - 총 컬럼 수: {qa_summary['final_data']['total_columns']}개\")\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T04:54:10.704019Z",
     "iopub.status.busy": "2026-01-12T04:54:10.703959Z",
     "iopub.status.idle": "2026-01-12T04:54:10.709691Z",
     "shell.execute_reply": "2026-01-12T04:54:10.709361Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QA 파일 저장 완료:\n",
      "  - /Users/yu_seok/Documents/workspace/nbCamp/Project/Yahoo Finance/Data_set/QA/full_period_companies.csv\n",
      "  - /Users/yu_seok/Documents/workspace/nbCamp/Project/Yahoo Finance/Data_set/QA/partial_period_companies.csv\n",
      "  - /Users/yu_seok/Documents/workspace/nbCamp/Project/Yahoo Finance/Data_set/QA/dividend_split_events.csv\n",
      "  - /Users/yu_seok/Documents/workspace/nbCamp/Project/Yahoo Finance/Data_set/QA/anomaly_report.csv\n",
      "  - /Users/yu_seok/Documents/workspace/nbCamp/Project/Yahoo Finance/Data_set/QA/qa_summary.json\n"
     ]
    }
   ],
   "source": [
    "# QA 파일 저장\n",
    "# 1. 동일 기간 비교 가능 기업\n",
    "full_period_df = company_stats[company_stats['Company'].isin(full_period_companies)]\n",
    "full_period_df.to_csv(QA_DIR / 'full_period_companies.csv', index=False)\n",
    "\n",
    "# 2. 개별 분석 대상 기업\n",
    "partial_period_df = company_stats[company_stats['Company'].isin(partial_period_companies)]\n",
    "partial_period_df.to_csv(QA_DIR / 'partial_period_companies.csv', index=False)\n",
    "\n",
    "# 3. 배당/분할 이벤트 기업\n",
    "if len(event_df) > 0:\n",
    "    event_df.to_csv(QA_DIR / 'dividend_split_events.csv', index=False)\n",
    "\n",
    "# 4. OHLC 이상치 리포트\n",
    "if len(anomaly_df) > 0:\n",
    "    anomaly_df.to_csv(QA_DIR / 'anomaly_report.csv', index=False)\n",
    "\n",
    "# 5. QA 요약 JSON\n",
    "with open(QA_DIR / 'qa_summary.json', 'w') as f:\n",
    "    json.dump(qa_summary, f, indent=2, default=str)\n",
    "\n",
    "print(\"QA 파일 저장 완료:\")\n",
    "print(f\"  - {QA_DIR / 'full_period_companies.csv'}\")\n",
    "print(f\"  - {QA_DIR / 'partial_period_companies.csv'}\")\n",
    "print(f\"  - {QA_DIR / 'dividend_split_events.csv'}\")\n",
    "print(f\"  - {QA_DIR / 'anomaly_report.csv'}\")\n",
    "print(f\"  - {QA_DIR / 'qa_summary.json'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-12T04:54:10.710678Z",
     "iopub.status.busy": "2026-01-12T04:54:10.710620Z",
     "iopub.status.idle": "2026-01-12T04:54:23.085119Z",
     "shell.execute_reply": "2026-01-12T04:54:23.084719Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[저장 완료]\n",
      "  1. Daily Master: (857401, 32) -> stock_daily_master.csv\n",
      "  2. Sector Summary: (20915, 9) -> stock_sector_summary.csv\n",
      "  3. Monthly Summary: (41737, 10) -> stock_monthly_summary.csv\n",
      "  4. Ticker Metadata: (491, 3) -> ticker_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "# 메인 데이터 저장\n",
    "df_final.to_csv(DATA_DIR / 'stock_daily_master.csv', index=False)\n",
    "df_sector.to_csv(DATA_DIR / 'stock_sector_summary.csv', index=False)\n",
    "df_monthly.to_csv(DATA_DIR / 'stock_monthly_summary.csv', index=False)\n",
    "\n",
    "# 메타데이터 저장\n",
    "metadata_df.to_csv(DATA_DIR / 'ticker_metadata.csv', index=False)\n",
    "\n",
    "print(\"\\n[저장 완료]\")\n",
    "print(f\"  1. Daily Master: {df_final.shape} -> stock_daily_master.csv\")\n",
    "print(f\"  2. Sector Summary: {df_sector.shape} -> stock_sector_summary.csv\")\n",
    "print(f\"  3. Monthly Summary: {df_monthly.shape} -> stock_monthly_summary.csv\")\n",
    "print(f\"  4. Ticker Metadata: {metadata_df.shape} -> ticker_metadata.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
